{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb695c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################\n",
    "##### machine learning script for constructivity ######\n",
    "## based upon the chatGPT_test_script2 script #########\n",
    "##########################################################################\n",
    "### Step 1: install packages - \n",
    "##### packages are necessary to install and load, given that they have the built in functions necessary to run complex tasks. \n",
    "## They effectively act as one of the most crucial time saving activities that would otherwise lead to overly long and \n",
    "## duplicative scripts. \n",
    "\n",
    "### note: you are not expected to remember all of these; just for the best to copy and paste these sections \n",
    "\n",
    "## read in pkgs \n",
    "import sys\n",
    "import os\n",
    "# !{sys.executable} -m pip install xgboost==1.7.5 # note: needed since it looks like anaconda installs an earlier version \n",
    "# of the package, which is not helpful. 1.7.5 allows for the categorical data of interest to be used. \n",
    "\n",
    "# !{sys.executable} -m pip install requests #; this code here can be used to install packages on anaconda/jupyter notebook \n",
    "### I believe the below should be installed by default \n",
    "import requests # web scraping \n",
    "from bs4 import BeautifulSoup # for web scraping \n",
    "import itertools # for efficient operation of loops \n",
    "import pandas as pd # necessary for reading in, creating, and manipulating data frames \n",
    "import csv ## for importing/exporting csvs \n",
    "import glob ## for finding files in path\n",
    "import re\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b0463f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import torch packages and such \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "### these were loaded in successfully "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0317fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your labeled dataset class\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, tokenizer, comments, labels):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = self.comments[index]\n",
    "        label = self.labels[index]\n",
    "        inputs = self.tokenizer.encode_plus(comment, add_special_tokens=True, padding='max_length', max_length=128, truncation=True)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2c1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and model configuration\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "#config = GPT2Config.from_pretrained('gpt2', num_labels=2)  # 2 classes: toxic and non-toxic; can expand as needed \n",
    "config = GPT2Config.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6936872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>quality_of_class</th>\n",
       "      <th>difficulty_of_class</th>\n",
       "      <th>class_code</th>\n",
       "      <th>college</th>\n",
       "      <th>prof_firstname</th>\n",
       "      <th>prof_lastname</th>\n",
       "      <th>comment</th>\n",
       "      <th>out_misrep</th>\n",
       "      <th>out_emo_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_origin</th>\n",
       "      <th>pb_nuero_div</th>\n",
       "      <th>pb_phys_able</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Only graded on 4 assignments (30% Midterm, 30%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Final grade is only based on two exams, readin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLITSC1100</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Class was super easy. One reading quiz a week ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Lecture could be dry at times, but I still lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>was an excellent lecturer. Insightful, even h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PSYCH1100H</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ANNA</td>\n",
       "      <td>YOCOM</td>\n",
       "      <td>I had Dr.  for PSYCH 1100H last semester, and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>17</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PSYCH2200</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ANNA</td>\n",
       "      <td>YOCOM</td>\n",
       "      <td>A great professor for this class. You only nee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PSY1100H</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ANNA</td>\n",
       "      <td>YOCOM</td>\n",
       "      <td>LOVED this class! Prof  made me want to attend...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>PSY2220</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ANNA</td>\n",
       "      <td>YOCOM</td>\n",
       "      <td>Dr.  made this class much better than I expect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>PSYCH1100H</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ANNA</td>\n",
       "      <td>YOCOM</td>\n",
       "      <td>If you come to class and listen you will be fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2800 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row  quality_of_class  difficulty_of_class   class_code  \\\n",
       "0       1               2.0                    4  POLITSC3500   \n",
       "1       2               3.0                    4  POLITSC3500   \n",
       "2       3               4.0                    1  POLITSC1100   \n",
       "3       4               4.0                    2  POLITSC3115   \n",
       "4       5               5.0                    3  POLITSC3115   \n",
       "...   ...               ...                  ...          ...   \n",
       "2795   16               5.0                    3   PSYCH1100H   \n",
       "2796   17               5.0                    3    PSYCH2200   \n",
       "2797   18               5.0                    3     PSY1100H   \n",
       "2798   19               5.0                    3      PSY2220   \n",
       "2799   20               5.0                    2   PSYCH1100H   \n",
       "\n",
       "                    college prof_firstname prof_lastname  \\\n",
       "0     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "1     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "2     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "3     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "4     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "...                     ...            ...           ...   \n",
       "2795  OHIO STATE UNIVERSITY           ANNA         YOCOM   \n",
       "2796  OHIO STATE UNIVERSITY           ANNA         YOCOM   \n",
       "2797  OHIO STATE UNIVERSITY           ANNA         YOCOM   \n",
       "2798  OHIO STATE UNIVERSITY           ANNA         YOCOM   \n",
       "2799  OHIO STATE UNIVERSITY           ANNA         YOCOM   \n",
       "\n",
       "                                                comment  out_misrep  \\\n",
       "0     Only graded on 4 assignments (30% Midterm, 30%...           0   \n",
       "1     Final grade is only based on two exams, readin...           0   \n",
       "2     Class was super easy. One reading quiz a week ...           0   \n",
       "3     Lecture could be dry at times, but I still lik...           0   \n",
       "4      was an excellent lecturer. Insightful, even h...           0   \n",
       "...                                                 ...         ...   \n",
       "2795  I had Dr.  for PSYCH 1100H last semester, and ...           0   \n",
       "2796  A great professor for this class. You only nee...           0   \n",
       "2797  LOVED this class! Prof  made me want to attend...           0   \n",
       "2798  Dr.  made this class much better than I expect...           0   \n",
       "2799  If you come to class and listen you will be fi...           0   \n",
       "\n",
       "      out_emo_lang  ...  pb_origin  pb_nuero_div  pb_phys_able  pb_pol_affil  \\\n",
       "0                0  ...        0.0           0.0             0           0.0   \n",
       "1                0  ...        0.0           0.0             0           0.0   \n",
       "2                0  ...        0.0           0.0             0           0.0   \n",
       "3                0  ...        0.0           0.0             0           0.0   \n",
       "4                0  ...        0.0           0.0             0           0.0   \n",
       "...            ...  ...        ...           ...           ...           ...   \n",
       "2795             0  ...        0.0           0.0             0           0.0   \n",
       "2796             0  ...        0.0           0.0             0           0.0   \n",
       "2797             0  ...        0.0           0.0             0           0.0   \n",
       "2798             0  ...        0.0           0.0             0           0.0   \n",
       "2799             0  ...        0.0           0.0             0           0.0   \n",
       "\n",
       "      complex  constructive  reflective  outrage_agg  personal_attack_agg  \\\n",
       "0           0             0           0            0                    0   \n",
       "1           1             0           0            0                    0   \n",
       "2           0             0           0            0                    0   \n",
       "3           0             0           1            0                    0   \n",
       "4           0             0           0            0                    0   \n",
       "...       ...           ...         ...          ...                  ...   \n",
       "2795        0             0           0            0                    0   \n",
       "2796        0             0           0            0                    0   \n",
       "2797        0             0           0            0                    0   \n",
       "2798        0             0           0            0                    0   \n",
       "2799        0             0           0            0                    0   \n",
       "\n",
       "      prejudice_agg  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "2795            0.0  \n",
       "2796            0.0  \n",
       "2797            0.0  \n",
       "2798            0.0  \n",
       "2799            0.0  \n",
       "\n",
       "[2800 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### import the data from OSU comments \n",
    "rmp_df = pd.read_csv('coding/text_cleaning_data/scored_rmp_data_osu_final.csv')\n",
    "rmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e33ffa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with that read in, let's get the comments and labels specified \n",
    "comments = rmp_df['comment']\n",
    "labels_const = rmp_df['constructive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2050029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labeled dataset object\n",
    "tokenizer.add_special_tokens({'pad_token': '0'})\n",
    "dataset = LabeledDataset(tokenizer, comments, labels_const) # tokenizer above (from gpt2), \n",
    "#with comments and labels from the RMP data set \n",
    "# and the labels the 0s and 1s \n",
    "\n",
    "# Data loader\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f678872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2178331e160>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Fine-tuning parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea023af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chek the labels just to be safe \n",
    "labels_const.unique() #good\n",
    "# the script below taking way too long; lets winnow down the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a00c46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3347,   373,   416,  1290,   262,  1266,  1534,    13,   329,   428,\n",
      "          1781,    13,  1375,  1718,  7685, 14262,  2587,   290,   925,   340,\n",
      "          3499,    13,  2332, 48258,   274,   389,  9389,   475,  8005,    33,\n",
      "         33076,   815,   423,  2761,   611,   484,  1100,   262,  1492,    13,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15],\n",
      "        [ 1639,   423,   284,  1394,   510,   351,  2035,  1016,   284,  1398,\n",
      "           393,  3555,   477,   262, 19392,   357,  4758,   389,   429,   477,\n",
      "           262,   835,  5901,   503,   290,   345,  2193,   617,  2846,   287,\n",
      "          1398,   691,   737,   632,  2492,   470,  1327,    11,   583,   384,\n",
      "            13,   383, 25917,  3588,   470,   477,   326,  7895, 13769,   262,\n",
      "          3182, 45291,  3842,    13,  1375,   318,   257,   922, 21187,    11,\n",
      "           345,   655,   423,   284,  1414,   845,  1969,  3241,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15,    15,    15,\n",
      "            15,    15,    15,    15,    15,    15,    15,    15]])\n",
      "tensor([0, 0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     19\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:1098\u001b[0m, in \u001b[0;36mGPT2LMHeadModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mset_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[0;32m   1096\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m-> 1098\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;66;03m# move labels to correct device to enable model parallelism\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The model itself. Let's see if we can't get this working \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    #print(\"got here\")\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        print(input_ids)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        print(labels)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "save_path = 'coding/models'\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4348432b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute '__getitem__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute '__getitem__'"
     ]
    }
   ],
   "source": [
    "#dataloader.__getitem__('input_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ef38aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2800"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) ## length is 1400 ; is half of what it is in dataset; doesn't seem to be driving issues here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea2d1328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels_const) # so this is a pandas object, yet it did not break the laptop script... though it did run A LOT w/out\n",
    "# doing anything. So maybe it is the pandas nature messing things up? What if we could recreate the error in the \n",
    "# chatGPT script? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f398ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
