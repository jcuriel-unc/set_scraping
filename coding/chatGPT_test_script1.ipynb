{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc7598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### install openai \n",
    "#!{sys.executable} -m pip install openai\n",
    "#import openai\n",
    "\n",
    "## read in pkgs \n",
    "import sys\n",
    "import os\n",
    "# !{sys.executable} -m pip install xgboost==1.7.5 # note: needed since it looks like anaconda installs an earlier version \n",
    "# of the package, which is not helpful. 1.7.5 allows for the categorical data of interest to be used. \n",
    "\n",
    "# !{sys.executable} -m pip install requests #; this code here can be used to install packages on anaconda/jupyter notebook \n",
    "### I believe the below should be installed by default \n",
    "import requests # web scraping \n",
    "from bs4 import BeautifulSoup # for web scraping \n",
    "import itertools # for efficient operation of loops \n",
    "import pandas as pd # necessary for reading in, creating, and manipulating data frames \n",
    "import csv ## for importing/exporting csvs \n",
    "import glob ## for finding files in path\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e1c45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\j-curiel\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - openai\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.5.7   |       h56e8100_0         145 KB  conda-forge\n",
      "    certifi-2023.5.7           |     pyhd8ed1ab_0         149 KB  conda-forge\n",
      "    openai-0.23.1              |     pyhd8ed1ab_0          43 KB  conda-forge\n",
      "    openssl-1.1.1u             |       h2bbff1b_0         5.5 MB\n",
      "    pandas-stubs-1.2.0.62      |   py39hcbf5309_0          85 KB  conda-forge\n",
      "    python_abi-3.9             |           2_cp39           4 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  openai             conda-forge/noarch::openai-0.23.1-pyhd8ed1ab_0 None\n",
      "  pandas-stubs       conda-forge/win-64::pandas-stubs-1.2.0.62-py39hcbf5309_0 None\n",
      "  python_abi         conda-forge/win-64::python_abi-3.9-2_cp39 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.01.10~ --> conda-forge::ca-certificates-2023.5.7-h56e8100_0 None\n",
      "  openssl                                 1.1.1t-h2bbff1b_0 --> 1.1.1u-h2bbff1b_0 None\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/win-64::certifi-2023.5.7-py~ --> conda-forge/noarch::certifi-2023.5.7-pyhd8ed1ab_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "ca-certificates-2023 | 145 KB    |            |   0% \n",
      "ca-certificates-2023 | 145 KB    | #1         |  11% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "ca-certificates-2023 | 145 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1u       | 5.5 MB    |            |   0% \n",
      "openssl-1.1.1u       | 5.5 MB    |            |   0% \n",
      "openssl-1.1.1u       | 5.5 MB    | 5          |   5% \n",
      "openssl-1.1.1u       | 5.5 MB    | ##4        |  24% \n",
      "openssl-1.1.1u       | 5.5 MB    | ####5      |  46% \n",
      "openssl-1.1.1u       | 5.5 MB    | ######8    |  68% \n",
      "openssl-1.1.1u       | 5.5 MB    | ########5  |  85% \n",
      "openssl-1.1.1u       | 5.5 MB    | ########## | 100% \n",
      "\n",
      "python_abi-3.9       | 4 KB      |            |   0% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "python_abi-3.9       | 4 KB      | ########## | 100% \n",
      "\n",
      "certifi-2023.5.7     | 149 KB    |            |   0% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "certifi-2023.5.7     | 149 KB    | ########## | 100% \n",
      "\n",
      "pandas-stubs-1.2.0.6 | 85 KB     |            |   0% \n",
      "pandas-stubs-1.2.0.6 | 85 KB     | ########## | 100% \n",
      "pandas-stubs-1.2.0.6 | 85 KB     | ########## | 100% \n",
      "\n",
      "openai-0.23.1        | 43 KB     |            |   0% \n",
      "openai-0.23.1        | 43 KB     | ########## | 100% \n",
      "openai-0.23.1        | 43 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e56f555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4545beed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie review does not belong to either of the categories.\n"
     ]
    }
   ],
   "source": [
    "### this is example code from: https://community.openai.com/t/compute-the-probability-of-input-text-for-classification/29840/3\n",
    "# I should be able to adapt this into what I need for the dimensional script \n",
    "import openai\n",
    "# openai.api_key = os.getenv('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')\n",
    "\n",
    "openai.api_key = \"\"\n",
    "\n",
    "prompt = '''\n",
    "A movie review can only belong to one of these categories: \"Just another superhero movie\" or \"Generic hype\".\n",
    "\n",
    "Which category does this movie review belong to?\n",
    "\"\"\"\n",
    "A thrill ride for the ages! --Peter K. Rosenthal\n",
    "\"\"\"\n",
    "'''\n",
    "\n",
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=prompt,\n",
    "                                    max_tokens=20,\n",
    "                                    temperature=0)\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e4d26ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp39-cp39-win_amd64.whl (635 kB)\n",
      "     -------------------------------------- 635.6/635.6 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\j-curiel\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\j-curiel\\anaconda3\\lib\\site-packages (from tiktoken) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\j-curiel\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\j-curiel\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\j-curiel\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\j-curiel\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2023.5.7)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.4.0\n"
     ]
    }
   ],
   "source": [
    "### install the tiktoken library \n",
    "!{sys.executable} -m pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52d7f0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good: 0.8\n",
      "Alright/OK: 0.2\n",
      "Bad: 0.0\n"
     ]
    }
   ],
   "source": [
    "## now lets try to have it return a probability \n",
    "openai.api_key = \"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\"\n",
    "model = 'text-davinci-003'\n",
    "prompt = '''\n",
    "A movie review can only belong to one of these categories: \"good\" or \"alright/ok\" or \"bad\".\n",
    "\n",
    "What is the probability it belongs to each one of these categories?\n",
    "\"\"\"\n",
    "A thrill ride for the ages! --Peter K. Rosenthal\n",
    "\"\"\"\n",
    "'''\n",
    "\n",
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=prompt,\n",
    "                                    max_tokens=20,\n",
    "                                    logprobs=1,\n",
    "                                    temperature=0)\n",
    "print(response['choices'][0]['text']) # excellent, this worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "646a03f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject at 0x1fa790f6810> JSON: {\n",
       "   \"finish_reason\": \"stop\",\n",
       "   \"index\": 0,\n",
       "   \"logprobs\": {\n",
       "     \"text_offset\": [\n",
       "       219,\n",
       "       223,\n",
       "       224,\n",
       "       226,\n",
       "       227,\n",
       "       228,\n",
       "       229,\n",
       "       236,\n",
       "       237,\n",
       "       239,\n",
       "       240,\n",
       "       242,\n",
       "       243,\n",
       "       244,\n",
       "       245,\n",
       "       248,\n",
       "       249,\n",
       "       251,\n",
       "       252\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -0.42900506,\n",
       "       -0.0015118337,\n",
       "       -0.22924997,\n",
       "       -6.827632e-08,\n",
       "       -0.99115306,\n",
       "       -0.45887905,\n",
       "       -0.0052777478,\n",
       "       -0.00013919984,\n",
       "       -0.6208614,\n",
       "       -6.337372e-05,\n",
       "       -3.583558e-05,\n",
       "       -2.3360508e-06,\n",
       "       -0.30333373,\n",
       "       -0.033837836,\n",
       "       -4.871012e-05,\n",
       "       -4.9308033e-05,\n",
       "       -8.6144464e-05,\n",
       "       -0.0004368883,\n",
       "       -4.9308033e-05\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \"Good\",\n",
       "       \":\",\n",
       "       \" 0\",\n",
       "       \".\",\n",
       "       \"8\",\n",
       "       \"\\n\",\n",
       "       \"Alright\",\n",
       "       \"/\",\n",
       "       \"OK\",\n",
       "       \":\",\n",
       "       \" 0\",\n",
       "       \".\",\n",
       "       \"2\",\n",
       "       \"\\n\",\n",
       "       \"Bad\",\n",
       "       \":\",\n",
       "       \" 0\",\n",
       "       \".\",\n",
       "       \"0\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \"Good\": -0.42900506\n",
       "       },\n",
       "       {\n",
       "         \":\": -0.0015118337\n",
       "       },\n",
       "       {\n",
       "         \" 0\": -0.22924997\n",
       "       },\n",
       "       {\n",
       "         \".\": -6.827632e-08\n",
       "       },\n",
       "       {\n",
       "         \"8\": -0.99115306\n",
       "       },\n",
       "       {\n",
       "         \"\\n\": -0.45887905\n",
       "       },\n",
       "       {\n",
       "         \"Alright\": -0.0052777478\n",
       "       },\n",
       "       {\n",
       "         \"/\": -0.00013919984\n",
       "       },\n",
       "       {\n",
       "         \"OK\": -0.6208614\n",
       "       },\n",
       "       {\n",
       "         \":\": -6.337372e-05\n",
       "       },\n",
       "       {\n",
       "         \" 0\": -3.583558e-05\n",
       "       },\n",
       "       {\n",
       "         \".\": -2.3360508e-06\n",
       "       },\n",
       "       {\n",
       "         \"2\": -0.30333373\n",
       "       },\n",
       "       {\n",
       "         \"\\n\": -0.033837836\n",
       "       },\n",
       "       {\n",
       "         \"Bad\": -4.871012e-05\n",
       "       },\n",
       "       {\n",
       "         \":\": -4.9308033e-05\n",
       "       },\n",
       "       {\n",
       "         \" 0\": -8.6144464e-05\n",
       "       },\n",
       "       {\n",
       "         \".\": -0.0004368883\n",
       "       },\n",
       "       {\n",
       "         \"0\": -4.9308033e-05\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   \"text\": \"Good: 0.8\\nAlright/OK: 0.2\\nBad: 0.0\"\n",
       " }]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'] ## gets the outcome "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "29aaeb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good: 0.8\\nAlright/OK: 0.2\\nBad: 0.0'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75f6524d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'completion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26160\\4203989261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# post-process to get what we want\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtiktoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mnum_completion_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# apply probability chain rule:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# log Pr(are ya | hey how) = log Pr(ya | hey how are) + log Pr(are | hey how)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'completion' is not defined"
     ]
    }
   ],
   "source": [
    "### how to get the probs from the model of interest \n",
    "import tiktoken\n",
    "model = 'text-davinci-003'\n",
    "\n",
    "# post-process to get what we want\n",
    "tokenizer = tiktoken.encoding_for_model(model)\n",
    "num_completion_tokens = len(tokenizer.encode(completion))\n",
    "# apply probability chain rule:\n",
    "# log Pr(are ya | hey how) = log Pr(ya | hey how are) + log Pr(are | hey how) \n",
    "logprob_completion_given_prefix = sum(token_logprobs[-num_completion_tokens:])\n",
    "prob_completion_given_prefix = 2.718 ** logprob_completion_given_prefix\n",
    "prob_completion_given_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5291315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good',\n",
       " ':',\n",
       " ' 0',\n",
       " '.',\n",
       " '8',\n",
       " '\\n',\n",
       " 'Alright',\n",
       " '/',\n",
       " 'OK',\n",
       " ':',\n",
       " ' 0',\n",
       " '.',\n",
       " '2',\n",
       " '\\n',\n",
       " 'Bad',\n",
       " ':',\n",
       " ' 0',\n",
       " '.',\n",
       " '0']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = response['choices'][0]['logprobs'][\"tokens\"]\n",
    "outcomes # so backslashes do change things. However, I believe that so long as we keep these consistent, we should be able \n",
    "# to get this more or less complete based on the static responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79726758",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26160\\1282771522.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extracting numbers from list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m res = list(map(lambda sub:int(''.join(\n\u001b[0m\u001b[0;32m      3\u001b[0m       [ele for ele in sub if ele.isnumeric()])), outcomes[2:5]))\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26160\\1282771522.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(sub)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extracting numbers from list of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m res = list(map(lambda sub:int(''.join(\n\u001b[0m\u001b[0;32m      3\u001b[0m       [ele for ele in sub if ele.isnumeric()])), outcomes[2:5]))\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Extracting numbers from list of strings\n",
    "res = list(map(lambda sub:int(''.join(\n",
    "      [ele for ele in sub if ele.isnumeric()])), outcomes[2:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e003734",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1=outcomes[2:5] # let's see if this holds up if we change the number of words in the categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed36d593",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1[0] += ''.join(prob1[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58473d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1\n",
    "del prob1[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad59e6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(prob1[0]) ### good, so this works. We should be able to take the above code then an manipulate it into a df. \n",
    "# we will need to do this for each of the probs of interest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "903ca672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>quality_of_class</th>\n",
       "      <th>difficulty_of_class</th>\n",
       "      <th>class_code</th>\n",
       "      <th>college</th>\n",
       "      <th>prof_firstname</th>\n",
       "      <th>prof_lastname</th>\n",
       "      <th>comment</th>\n",
       "      <th>out_misrep</th>\n",
       "      <th>out_emo_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_origin</th>\n",
       "      <th>pb_nuero_div</th>\n",
       "      <th>pb_phys_able</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Only graded on 4 assignments (30% Midterm, 30%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Final grade is only based on two exams, readin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLITSC1100</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Class was super easy. One reading quiz a week ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Lecture could be dry at times, but I still lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>was an excellent lecturer. Insightful, even h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC410</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>She's very fair. I got away with calling Karl ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Professor  is cool and all but her accent make...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Definitely not \"the greatest thing since slice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>She's not personal, almost to a harsh point. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>is an unpopular Sociology professor at OSU Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row  quality_of_class  difficulty_of_class   class_code  \\\n",
       "0       1               2.0                    4  POLITSC3500   \n",
       "1       2               3.0                    4  POLITSC3500   \n",
       "2       3               4.0                    1  POLITSC1100   \n",
       "3       4               4.0                    2  POLITSC3115   \n",
       "4       5               5.0                    3  POLITSC3115   \n",
       "...   ...               ...                  ...          ...   \n",
       "1095    4               4.0                    4       SOC410   \n",
       "1096    5               2.0                    4       SOC101   \n",
       "1097    6               1.0                    4       SOC101   \n",
       "1098    7               2.0                    4       SOC101   \n",
       "1099    8               2.0                    4       SOC101   \n",
       "\n",
       "                    college prof_firstname prof_lastname  \\\n",
       "0     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "1     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "2     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "3     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "4     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "...                     ...            ...           ...   \n",
       "1095  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1096  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1097  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1098  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1099  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "\n",
       "                                                comment  out_misrep  \\\n",
       "0     Only graded on 4 assignments (30% Midterm, 30%...           0   \n",
       "1     Final grade is only based on two exams, readin...           0   \n",
       "2     Class was super easy. One reading quiz a week ...           0   \n",
       "3     Lecture could be dry at times, but I still lik...           0   \n",
       "4      was an excellent lecturer. Insightful, even h...           0   \n",
       "...                                                 ...         ...   \n",
       "1095  She's very fair. I got away with calling Karl ...           0   \n",
       "1096  Professor  is cool and all but her accent make...           0   \n",
       "1097  Definitely not \"the greatest thing since slice...           0   \n",
       "1098  She's not personal, almost to a harsh point. T...           0   \n",
       "1099   is an unpopular Sociology professor at OSU Ma...           0   \n",
       "\n",
       "      out_emo_lang  ...  pb_origin  pb_nuero_div  pb_phys_able  pb_pol_affil  \\\n",
       "0                0  ...        0.0             0             0           0.0   \n",
       "1                0  ...        0.0             0             0           0.0   \n",
       "2                0  ...        0.0             0             0           0.0   \n",
       "3                0  ...        0.0             0             0           0.0   \n",
       "4                0  ...        0.0             0             0           0.0   \n",
       "...            ...  ...        ...           ...           ...           ...   \n",
       "1095             0  ...        0.0             0             0           0.0   \n",
       "1096             0  ...        0.0             0             0           0.0   \n",
       "1097             0  ...        0.0             0             0           0.0   \n",
       "1098             0  ...        0.0             0             0           0.0   \n",
       "1099             0  ...        0.0             0             0           0.0   \n",
       "\n",
       "      complex  constructive  reflective  outrage_agg  personal_attack_agg  \\\n",
       "0           0             0           0            0                    0   \n",
       "1           1             0           0            0                    0   \n",
       "2           0             0           0            0                    0   \n",
       "3           0             0           1            0                    0   \n",
       "4           0             0           0            0                    0   \n",
       "...       ...           ...         ...          ...                  ...   \n",
       "1095        0             0           0            0                    0   \n",
       "1096        0             0           0            0                    0   \n",
       "1097        0             0           0            1                    0   \n",
       "1098        0             0           0            1                    1   \n",
       "1099        0             0           0            1                    1   \n",
       "\n",
       "      prejudice_agg  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "1095            0.0  \n",
       "1096            0.0  \n",
       "1097            0.0  \n",
       "1098            0.0  \n",
       "1099            0.0  \n",
       "\n",
       "[1100 rows x 34 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### Let's try to apply this to our examples \n",
    "#### read in the data \n",
    "rmp_df = pd.read_csv(\"text_cleaning_data/scored_rmp_data06212023.csv\")\n",
    "rmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "104c5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now lets create a prompt \n",
    "test_msg = rmp_df['comment'][0]\n",
    "\n",
    "misrep_prompt = '''\n",
    "Calculate the probability that a comment belongs to each of the following ordinal categories: \"misrepresentation\" or\n",
    "\"somewhat misrepresentation\" or \"not misrepresentation\". A comment that is misreprsentation is a statement that engages \n",
    "in the logical fallacies of straw man or misrepresentation of empirical data/actions. \n",
    "Such statements assign malintent by a person and uses hyperbole to the point of absurdity.\n",
    "\n",
    "An example of a statement that is misrepresentation: The professor wants their students to fail and suffer. \n",
    "She literally could not teach if her life depended on it. \n",
    "\n",
    "\n",
    "A statement that is somewhat misrepresentation: she also assigns busy work that is completely pointless. \n",
    "And she is annoying-exaggerates her lame east coast accent. \n",
    "\n",
    "A statement that is not misrepresentation: His lectures were boring, but he gave us handouts to follow along with, \n",
    "so that was helpful\n",
    "\n",
    "\n",
    "What is the probability a comment belongs to each one of these categories?\n",
    "\"\"\"\n",
    "Only graded on 4 assignments (30% Midterm, 30% Final, 20% Reading Quizzes, 20% Group Project). Extremely dry, boring content, kind of assumes everyone has an advanced level of knowledge even though there are no pre reqs to the class. Exams are unnecessarily difficult - both the midterm and final had to be curved by 20 points each.\n",
    "\"\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6c8c18ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misrepresentation: 0%\n",
      "Somewhat Misrepresentation: 0%\n",
      "Not Misrepresentation: 100%\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=misrep_prompt,\n",
    "                                    max_tokens=30,\n",
    "                                    logprobs=1,\n",
    "                                    temperature=0)\n",
    "print(response['choices'][0]['text']) # good, this seems to work. \n",
    "### now we just need to figure out how to get the data frame entries loaded in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2cb60106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " 'Cal',\n",
       " 'cul',\n",
       " 'ate',\n",
       " ' the',\n",
       " ' probability',\n",
       " ' that',\n",
       " ' a',\n",
       " ' comment',\n",
       " ' belongs',\n",
       " ' to',\n",
       " ' each',\n",
       " ' of',\n",
       " ' the',\n",
       " ' following',\n",
       " ' ord',\n",
       " 'inal',\n",
       " ' categories',\n",
       " ':',\n",
       " ' \"',\n",
       " 'mis',\n",
       " 'represent',\n",
       " 'ation',\n",
       " '\"',\n",
       " ' or',\n",
       " '\\n',\n",
       " '\"',\n",
       " 's',\n",
       " 'omew',\n",
       " 'hat',\n",
       " ' misrepresent',\n",
       " 'ation',\n",
       " '\"',\n",
       " ' or',\n",
       " ' \"',\n",
       " 'not',\n",
       " ' misrepresent',\n",
       " 'ation',\n",
       " '\".',\n",
       " ' A',\n",
       " ' comment',\n",
       " ' that',\n",
       " ' is',\n",
       " ' mis',\n",
       " 're',\n",
       " 'pr',\n",
       " 'sent',\n",
       " 'ation',\n",
       " ' is',\n",
       " ' a',\n",
       " ' statement',\n",
       " ' that',\n",
       " ' engages',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'in',\n",
       " ' the',\n",
       " ' logical',\n",
       " ' fall',\n",
       " 'acies',\n",
       " ' of',\n",
       " ' straw',\n",
       " ' man',\n",
       " ' or',\n",
       " ' misrepresent',\n",
       " 'ation',\n",
       " ' of',\n",
       " ' empirical',\n",
       " ' data',\n",
       " '/',\n",
       " 'actions',\n",
       " '.',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'Such',\n",
       " ' statements',\n",
       " ' assign',\n",
       " ' mal',\n",
       " 'intent',\n",
       " ' by',\n",
       " ' a',\n",
       " ' person',\n",
       " ' and',\n",
       " ' uses',\n",
       " ' hyper',\n",
       " 'bole',\n",
       " ' to',\n",
       " ' the',\n",
       " ' point',\n",
       " ' of',\n",
       " ' absurdity',\n",
       " '.',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'An',\n",
       " ' example',\n",
       " ' of',\n",
       " ' a',\n",
       " ' statement',\n",
       " ' that',\n",
       " ' is',\n",
       " ' misrepresent',\n",
       " 'ation',\n",
       " ':',\n",
       " ' The',\n",
       " ' professor',\n",
       " ' wants',\n",
       " ' their',\n",
       " ' students',\n",
       " ' to',\n",
       " ' fail',\n",
       " ' and',\n",
       " ' suffer',\n",
       " '.',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'She',\n",
       " ' literally',\n",
       " ' could',\n",
       " ' not',\n",
       " ' teach',\n",
       " ' if',\n",
       " ' her',\n",
       " ' life',\n",
       " ' depended',\n",
       " ' on',\n",
       " ' it',\n",
       " '.',\n",
       " '\\xa0',\n",
       " '\\n\\n',\n",
       " '\\n',\n",
       " 'A',\n",
       " ' statement',\n",
       " ' that',\n",
       " ' is',\n",
       " ' somewhat',\n",
       " ' misrepresent',\n",
       " 'ation',\n",
       " ':',\n",
       " ' she',\n",
       " ' also',\n",
       " ' assigns',\n",
       " ' busy',\n",
       " ' work',\n",
       " ' that',\n",
       " ' is',\n",
       " ' completely',\n",
       " ' pointless',\n",
       " '.',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'And',\n",
       " ' she',\n",
       " ' is',\n",
       " ' annoying',\n",
       " '-',\n",
       " 'ex',\n",
       " 'agger',\n",
       " 'ates',\n",
       " ' her',\n",
       " ' lame',\n",
       " ' east',\n",
       " ' coast',\n",
       " ' accent',\n",
       " '.',\n",
       " ' ',\n",
       " '\\n',\n",
       " '\\n',\n",
       " 'A',\n",
       " ' statement',\n",
       " ' that',\n",
       " ' is',\n",
       " ' not',\n",
       " ' misrepresent',\n",
       " 'ation',\n",
       " ':',\n",
       " ' His',\n",
       " ' lectures',\n",
       " ' were',\n",
       " ' boring',\n",
       " ',',\n",
       " ' but',\n",
       " ' he',\n",
       " ' gave',\n",
       " ' us',\n",
       " ' hand',\n",
       " 'outs',\n",
       " ' to',\n",
       " ' follow',\n",
       " ' along',\n",
       " ' with',\n",
       " ',',\n",
       " ' ',\n",
       " '\\n',\n",
       " 'so',\n",
       " ' that',\n",
       " ' was',\n",
       " ' helpful',\n",
       " '\\n\\n',\n",
       " '\\n',\n",
       " 'What',\n",
       " ' is',\n",
       " ' the',\n",
       " ' probability',\n",
       " ' a',\n",
       " ' comment',\n",
       " ' belongs',\n",
       " ' to',\n",
       " ' each',\n",
       " ' one',\n",
       " ' of',\n",
       " ' these',\n",
       " ' categories',\n",
       " '?',\n",
       " '\\n',\n",
       " '\"\"\"',\n",
       " '\\n',\n",
       " 'Only',\n",
       " ' graded',\n",
       " ' on',\n",
       " ' 4',\n",
       " ' assignments',\n",
       " ' (',\n",
       " '30',\n",
       " '%',\n",
       " ' Mid',\n",
       " 'term',\n",
       " ',',\n",
       " ' 30',\n",
       " '%',\n",
       " ' Final',\n",
       " ',',\n",
       " ' 20',\n",
       " '%',\n",
       " ' Reading',\n",
       " ' Qu',\n",
       " 'izz',\n",
       " 'es',\n",
       " ',',\n",
       " ' 20',\n",
       " '%',\n",
       " ' Group',\n",
       " ' Project',\n",
       " ').',\n",
       " ' Extreme',\n",
       " 'ly',\n",
       " ' dry',\n",
       " ',',\n",
       " ' boring',\n",
       " ' content',\n",
       " ',',\n",
       " ' kind',\n",
       " ' of',\n",
       " ' assumes',\n",
       " ' everyone',\n",
       " ' has',\n",
       " ' an',\n",
       " ' advanced',\n",
       " ' level',\n",
       " ' of',\n",
       " ' knowledge',\n",
       " ' even',\n",
       " ' though',\n",
       " ' there',\n",
       " ' are',\n",
       " ' no',\n",
       " ' pre',\n",
       " ' req',\n",
       " 's',\n",
       " ' to',\n",
       " ' the',\n",
       " ' class',\n",
       " '.',\n",
       " ' Ex',\n",
       " 'ams',\n",
       " ' are',\n",
       " ' unnecessarily',\n",
       " ' difficult',\n",
       " ' -',\n",
       " ' both',\n",
       " ' the',\n",
       " ' midterm',\n",
       " ' and',\n",
       " ' final',\n",
       " ' had',\n",
       " ' to',\n",
       " ' be',\n",
       " ' curved',\n",
       " ' by',\n",
       " ' 20',\n",
       " ' points',\n",
       " ' each',\n",
       " '.',\n",
       " '\\n',\n",
       " '\"\"\"',\n",
       " '\\n',\n",
       " 'Mis',\n",
       " 'represent',\n",
       " 'ation',\n",
       " ':',\n",
       " ' 0',\n",
       " '%',\n",
       " '\\n',\n",
       " 'S',\n",
       " 'omew',\n",
       " 'hat',\n",
       " ' Mis',\n",
       " 'represent',\n",
       " 'ation',\n",
       " ':',\n",
       " ' 0',\n",
       " '%',\n",
       " '\\n',\n",
       " 'Not',\n",
       " ' Mis',\n",
       " 'represent',\n",
       " 'ation',\n",
       " ':',\n",
       " ' 100',\n",
       " '%']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = response['choices'][0]['logprobs'][\"tokens\"]\n",
    "outcomes # so backslashes do change things. However, I believe that so long as we keep these consistent, we should be able \n",
    "# to get this more or less complete based on the static responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "84c42750",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26160\\2570034096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#prob1[0] += ''.join(prob1[1:3])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msmallerlist1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0msmallerlist1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "## extract portion of interest \n",
    "delim = '\\n'\n",
    "smallerlist = [l.split(',') for l in ','.join(outcomes).split('\\n')] # good; this separates into 4 lists. WE need to grab \n",
    "# elements 1:3, skipping the 0th. \n",
    "\n",
    "smallerlist1 = smallerlist[1]\n",
    "# re.findall(r'\\d+', smallerlist[1] )\n",
    "#prob1[0] += ''.join(prob1[1:3])\n",
    "\n",
    "for t in smallerlist1.split():\n",
    "    try:\n",
    "        smallerlist1.append(float(t))\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "### create a fxn to extract \n",
    "#getVals = list([val for val in smallerlist[1]\n",
    "#            if val.isalpha() or val.isnumeric()])\n",
    " \n",
    "#strp_vals = \"\".join(getVals)\n",
    " \n",
    "# printing final string\n",
    "#print (\"final string\", val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "84733f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now lets create a prompt \n",
    "test_msg = rmp_df['comment'][0]\n",
    "\n",
    "misrep_prompt = f'''\n",
    "Calculate the probability that a comment belongs to each of the following ordinal categories: \"misrepresentation\" or\n",
    "\"somewhat misrepresentation\" or \"not misrepresentation\". A comment that is misreprsentation is a statement that engages \n",
    "in the logical fallacies of straw man or misrepresentation of empirical data/actions. \n",
    "Such statements assign malintent by a person and uses hyperbole to the point of absurdity.\n",
    "\n",
    "An example of a statement that is misrepresentation: The professor wants their students to fail and suffer. \n",
    "She literally could not teach if her life depended on it. \n",
    "\n",
    "\n",
    "A statement that is somewhat misrepresentation: she also assigns busy work that is completely pointless. \n",
    "And she is annoying-exaggerates her lame east coast accent. \n",
    "\n",
    "A statement that is not misrepresentation: His lectures were boring, but he gave us handouts to follow along with, \n",
    "so that was helpful\n",
    "\n",
    "\n",
    "What is the probability a comment belongs to each one of these categories?\n",
    "\"\"\"\n",
    "{test_msg}\n",
    "\"\"\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3cfa2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=misrep_prompt,\n",
    "                                    max_tokens=30,\n",
    "                                    logprobs=1)\n",
    "#print(response['choices'][0]['text']) # good, this seems to work. \n",
    "### excellent! So the key is to have the f at the beginning, and then curly bracket in objects. So, now I should be able \n",
    "# to loop through the df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c2a76407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logprobs = response['choices'][0]['logprobs']['tokens']\n",
    "### let's try combining all elements \n",
    "l = ' '.join(token_logprobs)\n",
    "#l \n",
    "## now let's split and extract only numbers \n",
    "temp = re.findall(r'\\d+', l)\n",
    "res = list(map(int, temp))\n",
    "res[2] ### excellent, this works!!! now, I think that we should be able to run this loop \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5fd807fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now we will want to create the column in the new data frame, and also read in the data of interest from persp\n",
    "rmp_df_sub = pd.read_csv(\"sample_peRspective_coded342obs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3d2d5c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>FLIRTATION</th>\n",
       "      <th>ATTACK_ON_AUTHOR</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "      <th>openai_is_misrep_prob</th>\n",
       "      <th>openai_somewhat_misrep_prob</th>\n",
       "      <th>openai_not_misrep_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.013152</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.247846</td>\n",
       "      <td>0.264617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009</td>\n",
       "      <td>0.112437</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.042080</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.331722</td>\n",
       "      <td>0.625810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.209196</td>\n",
       "      <td>0.387362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>0.036399</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>0.016275</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>0.226716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016</td>\n",
       "      <td>0.187442</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.027001</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>0.628583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>985</td>\n",
       "      <td>0.351861</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.227703</td>\n",
       "      <td>0.352205</td>\n",
       "      <td>0.227896</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.456535</td>\n",
       "      <td>0.564237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>988</td>\n",
       "      <td>0.338998</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>0.340328</td>\n",
       "      <td>0.099306</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.675417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>990</td>\n",
       "      <td>0.452437</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.493893</td>\n",
       "      <td>0.109209</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>0.788002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>995</td>\n",
       "      <td>0.286744</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.269578</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.170271</td>\n",
       "      <td>0.872965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>998</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.264802</td>\n",
       "      <td>0.791277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_id  TOXICITY  SEVERE_TOXICITY  IDENTITY_ATTACK    INSULT  PROFANITY  \\\n",
       "0       1001  0.052800         0.001554         0.004717  0.024511   0.021808   \n",
       "1       1009  0.112437         0.001841         0.004532  0.042080   0.027820   \n",
       "2       1010  0.006440         0.000668         0.002127  0.006401   0.011321   \n",
       "3       1013  0.036399         0.000877         0.002266  0.019999   0.016275   \n",
       "4       1016  0.187442         0.002069         0.002719  0.094167   0.027001   \n",
       "..       ...       ...              ...              ...       ...        ...   \n",
       "337      985  0.351861         0.010529         0.006327  0.227703   0.352205   \n",
       "338      988  0.338998         0.007668         0.011469  0.340328   0.099306   \n",
       "339      990  0.452437         0.009346         0.008103  0.493893   0.109209   \n",
       "340      995  0.286744         0.003338         0.006068  0.269578   0.023995   \n",
       "341      998  0.022257         0.000753         0.002627  0.011959   0.012961   \n",
       "\n",
       "     SEXUALLY_EXPLICIT    THREAT  FLIRTATION  ATTACK_ON_AUTHOR  ...  \\\n",
       "0             0.013152  0.007547    0.247846          0.264617  ...   \n",
       "1             0.014272  0.007767    0.331722          0.625810  ...   \n",
       "2             0.005898  0.006557    0.209196          0.387362  ...   \n",
       "3             0.006045  0.006298    0.350796          0.226716  ...   \n",
       "4             0.004807  0.006803    0.375103          0.628583  ...   \n",
       "..                 ...       ...         ...               ...  ...   \n",
       "337           0.227896  0.006693    0.456535          0.564237  ...   \n",
       "338           0.014096  0.008492    0.361905          0.675417  ...   \n",
       "339           0.008670  0.007288    0.289088          0.788002  ...   \n",
       "340           0.008552  0.006770    0.170271          0.872965  ...   \n",
       "341           0.006104  0.006434    0.264802          0.791277  ...   \n",
       "\n",
       "     pb_pol_affil  complex  constructive  reflective  outrage_agg  \\\n",
       "0             0.0        0             0           0            0   \n",
       "1             0.0        0             0           0            1   \n",
       "2             0.0        0             0           0            0   \n",
       "3             0.0        0             0           0            0   \n",
       "4             0.0        0             0           0            1   \n",
       "..            ...      ...           ...         ...          ...   \n",
       "337           0.0        0             0           0            0   \n",
       "338           0.0        0             0           0            0   \n",
       "339           0.0        0             0           0            3   \n",
       "340           0.0        0             0           0            2   \n",
       "341           0.0        0             0           0            0   \n",
       "\n",
       "     personal_attack_agg  prejudice_agg openai_is_misrep_prob  \\\n",
       "0                      0            0.0                   -99   \n",
       "1                      0            0.0                   -99   \n",
       "2                      0            0.0                   -99   \n",
       "3                      0            0.0                   -99   \n",
       "4                      1            0.0                   -99   \n",
       "..                   ...            ...                   ...   \n",
       "337                    0            0.0                   -99   \n",
       "338                    0            0.0                   -99   \n",
       "339                    0            0.0                   -99   \n",
       "340                    2            0.0                   -99   \n",
       "341                    0            0.0                   -99   \n",
       "\n",
       "    openai_somewhat_misrep_prob openai_not_misrep_prob  \n",
       "0                           -99                    -99  \n",
       "1                           -99                    -99  \n",
       "2                           -99                    -99  \n",
       "3                           -99                    -99  \n",
       "4                           -99                    -99  \n",
       "..                          ...                    ...  \n",
       "337                         -99                    -99  \n",
       "338                         -99                    -99  \n",
       "339                         -99                    -99  \n",
       "340                         -99                    -99  \n",
       "341                         -99                    -99  \n",
       "\n",
       "[342 rows x 51 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now create three new columns\n",
    "rmp_df_sub['openai_is_misrep_prob'] = -99\n",
    "rmp_df_sub['openai_somewhat_misrep_prob'] = -99\n",
    "rmp_df_sub['openai_not_misrep_prob'] = -99\n",
    "rmp_df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d969d37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Error occurred for observation  1001\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_26160\\3868830309.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rmp_df_sub['openai_is_misrep_prob'][i] = res[0]\n",
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_26160\\3868830309.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rmp_df_sub['openai_somewhat_misrep_prob'][i] = res[1]\n",
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_26160\\3868830309.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rmp_df_sub['openai_not_misrep_prob'][i] = res[2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "Error occurred for observation  1024\n",
      "9\n",
      "10\n",
      "11\n",
      "Error occurred for observation  1039\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Error occurred for observation  1054\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "Error occurred for observation  124\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "Error occurred for observation  174\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "### attempt at loop \n",
    "comment_list = rmp_df_sub['comment']\n",
    "for i, element in enumerate(comment_list):\n",
    "    misrep_prompt = f'''\n",
    "    Calculate the probability that a comment belongs to each of the following ordinal categories: \"misrepresentation\" or\n",
    "    \"somewhat misrepresentation\" or \"not misrepresentation\". A comment that is misreprsentation is a statement that engages \n",
    "    in the logical fallacies of straw man or misrepresentation of empirical data/actions. \n",
    "    Such statements assign malintent by a person and uses hyperbole to the point of absurdity.\n",
    "\n",
    "    An example of a statement that is misrepresentation: The professor wants their students to fail and suffer. \n",
    "    She literally could not teach if her life depended on it. \n",
    "\n",
    "\n",
    "    A statement that is somewhat misrepresentation: she also assigns busy work that is completely pointless. \n",
    "    And she is annoying-exaggerates her lame east coast accent. \n",
    "\n",
    "    A statement that is not misrepresentation: His lectures were boring, but he gave us handouts to follow along with, \n",
    "    so that was helpful\n",
    "\n",
    "\n",
    "    What is the probability a comment belongs to each one of these categories?\n",
    "    \"\"\"\n",
    "    {comment_list[i]}\n",
    "    \"\"\"\n",
    "    '''\n",
    "    print(i)\n",
    "    ### try here; pass otherwise and gen individually \n",
    "    try:\n",
    "        response = openai.Completion.create(model='text-davinci-003',\n",
    "                                        prompt=misrep_prompt,\n",
    "                                        max_tokens=200, # content getting cut off; not ideal, but ah well \n",
    "                                        logprobs=1)\n",
    "    ## now grab the probs \n",
    "        token_logprobs = response['choices'][0]['logprobs']['tokens']\n",
    "### let's try combining all elements \n",
    "        l = ' '.join(token_logprobs)\n",
    "#l \n",
    "## now let's split and extract only numbers \n",
    "        temp = re.findall(r'\\d+', l)\n",
    "        res = list(map(int, temp))\n",
    "    ### now that we have a list of the three probs, let's store.\n",
    "    ## note. The first val is misrep, second somewhat misrep, and third not misrep \n",
    "        rmp_df_sub['openai_is_misrep_prob'][i] = res[0]\n",
    "        rmp_df_sub['openai_somewhat_misrep_prob'][i] = res[1]\n",
    "        rmp_df_sub['openai_not_misrep_prob'][i] = res[2]\n",
    "        ## seems to be that if something cannot be calculated (i.e. not enough info) then it has an error; can usually \n",
    "        # code as not misrep \n",
    "    except: # report the observation num (with 0 being 1) that failed to store/run \n",
    "        pass\n",
    "        print(\"Error occurred for observation \", rmp_df_sub['text_id'][i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1029d24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred for observation  68\n"
     ]
    }
   ],
   "source": [
    "# comment_list[8]\n",
    "print(\"Error occurred for observation \", rmp_df_sub['text_id'][232])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9277b3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Straight forward class: midterm, final, and paper'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmp_df_sub['comment'][232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "55be27d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### let's diagnose the code here \n",
    "misrep_prompt = f'''\n",
    "    Calculate the probability that a comment belongs to each of the following ordinal categories: \"misrepresentation\" or\n",
    "    \"somewhat misrepresentation\" or \"not misrepresentation\". A comment that is misreprsentation is a statement that engages \n",
    "    in the logical fallacies of straw man or misrepresentation of empirical data/actions. \n",
    "    Such statements assign malintent by a person and uses hyperbole to the point of absurdity.\n",
    "\n",
    "    An example of a statement that is misrepresentation: The professor wants their students to fail and suffer. \n",
    "    She literally could not teach if her life depended on it. \n",
    "\n",
    "\n",
    "    A statement that is somewhat misrepresentation: she also assigns busy work that is completely pointless. \n",
    "    And she is annoying-exaggerates her lame east coast accent. \n",
    "\n",
    "    A statement that is not misrepresentation: His lectures were boring, but he gave us handouts to follow along with, \n",
    "    so that was helpful\n",
    "\n",
    "\n",
    "    What is the probability a comment belongs to each one of these categories?\n",
    "    \"\"\"\n",
    "    {comment_list[232]}\n",
    "    \"\"\"\n",
    "    '''\n",
    "response = openai.Completion.create(model='text-davinci-003',\n",
    "                                    prompt=misrep_prompt,\n",
    "                                    max_tokens=200,\n",
    "                                    logprobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "589cee1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7VNxFUYMRlq4J2xgA1kHu65T2XRD0 at 0x1fa7d1a4720> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": {\n",
       "        \"text_offset\": [\n",
       "          1087,\n",
       "          1088,\n",
       "          1091,\n",
       "          1103,\n",
       "          1105,\n",
       "          1113,\n",
       "          1121,\n",
       "          1124,\n",
       "          1129,\n",
       "          1133,\n",
       "          1136,\n",
       "          1142,\n",
       "          1153,\n",
       "          1160,\n",
       "          1163,\n",
       "          1174,\n",
       "          1175,\n",
       "          1181,\n",
       "          1184,\n",
       "          1187,\n",
       "          1191,\n",
       "          1193,\n",
       "          1200,\n",
       "          1215,\n",
       "          1223,\n",
       "          1224,\n",
       "          1239,\n",
       "          1248,\n",
       "          1256,\n",
       "          1266,\n",
       "          1272,\n",
       "          1275,\n",
       "          1280,\n",
       "          1282,\n",
       "          1286,\n",
       "          1289,\n",
       "          1294,\n",
       "          1299,\n",
       "          1300,\n",
       "          1303,\n",
       "          1306,\n",
       "          1315,\n",
       "          1319,\n",
       "          1329,\n",
       "          1332,\n",
       "          1338,\n",
       "          1341,\n",
       "          1351,\n",
       "          1355,\n",
       "          1367,\n",
       "          1370,\n",
       "          1372,\n",
       "          1380,\n",
       "          1390,\n",
       "          1393,\n",
       "          1395,\n",
       "          1401,\n",
       "          1410\n",
       "        ],\n",
       "        \"token_logprobs\": [\n",
       "          -0.029300166,\n",
       "          -1.1043117,\n",
       "          -0.029730385,\n",
       "          -3.0455756,\n",
       "          -0.003178782,\n",
       "          -0.0026436392,\n",
       "          -0.018191135,\n",
       "          -0.14374322,\n",
       "          -1.2312167,\n",
       "          -0.0008370333,\n",
       "          -0.07059106,\n",
       "          -0.0048575546,\n",
       "          -0.36430338,\n",
       "          -0.0046433923,\n",
       "          -1.6336511,\n",
       "          -1.5529519,\n",
       "          -2.7066357,\n",
       "          -1.9921365,\n",
       "          -0.23754029,\n",
       "          -0.5212061,\n",
       "          -0.19534627,\n",
       "          -5.216409,\n",
       "          -0.6942535,\n",
       "          -0.3105902,\n",
       "          -0.14003743,\n",
       "          -4.1434717,\n",
       "          -0.30810335,\n",
       "          -1.178497,\n",
       "          -7.4953604,\n",
       "          -2.186006,\n",
       "          -0.0040128487,\n",
       "          -0.15083049,\n",
       "          -2.2657077,\n",
       "          -1.3510612,\n",
       "          -0.00027995434,\n",
       "          -0.7051607,\n",
       "          -3.1014132,\n",
       "          -0.64988846,\n",
       "          -0.8227687,\n",
       "          -0.22298871,\n",
       "          -2.3997746,\n",
       "          -1.1152806,\n",
       "          -3.7302916,\n",
       "          -0.774565,\n",
       "          -0.0043438445,\n",
       "          -0.008558814,\n",
       "          -0.6564563,\n",
       "          -0.37508067,\n",
       "          -0.3235707,\n",
       "          -0.43169498,\n",
       "          -0.34355155,\n",
       "          -0.23089445,\n",
       "          -0.0132514285,\n",
       "          -0.0139402235,\n",
       "          -0.5818733,\n",
       "          -3.0414028,\n",
       "          -0.018185612,\n",
       "          -0.0020094581\n",
       "        ],\n",
       "        \"tokens\": [\n",
       "          \"\\n\",\n",
       "          \"The\",\n",
       "          \" probability\",\n",
       "          \" a\",\n",
       "          \" comment\",\n",
       "          \" belongs\",\n",
       "          \" to\",\n",
       "          \" each\",\n",
       "          \" one\",\n",
       "          \" of\",\n",
       "          \" these\",\n",
       "          \" categories\",\n",
       "          \" cannot\",\n",
       "          \" be\",\n",
       "          \" calculated\",\n",
       "          \",\",\n",
       "          \" since\",\n",
       "          \" it\",\n",
       "          \" is\",\n",
       "          \" not\",\n",
       "          \" a\",\n",
       "          \" simple\",\n",
       "          \" classification\",\n",
       "          \" problem\",\n",
       "          \".\",\n",
       "          \" Classification\",\n",
       "          \" problems\",\n",
       "          \" require\",\n",
       "          \" different\",\n",
       "          \" types\",\n",
       "          \" of\",\n",
       "          \" data\",\n",
       "          \" (\",\n",
       "          \"such\",\n",
       "          \" as\",\n",
       "          \" text\",\n",
       "          \" data\",\n",
       "          \")\",\n",
       "          \" to\",\n",
       "          \" be\",\n",
       "          \" analyzed\",\n",
       "          \" and\",\n",
       "          \" evaluated\",\n",
       "          \" in\",\n",
       "          \" order\",\n",
       "          \" to\",\n",
       "          \" determine\",\n",
       "          \" the\",\n",
       "          \" probability\",\n",
       "          \" of\",\n",
       "          \" a\",\n",
       "          \" comment\",\n",
       "          \" belonging\",\n",
       "          \" to\",\n",
       "          \" a\",\n",
       "          \" given\",\n",
       "          \" category\",\n",
       "          \".\"\n",
       "        ],\n",
       "        \"top_logprobs\": [\n",
       "          {\n",
       "            \"\\n\": -0.029300166\n",
       "          },\n",
       "          {\n",
       "            \"Mis\": -1.0470282\n",
       "          },\n",
       "          {\n",
       "            \" probability\": -0.029730385\n",
       "          },\n",
       "          {\n",
       "            \" that\": -0.52597606\n",
       "          },\n",
       "          {\n",
       "            \" comment\": -0.003178782\n",
       "          },\n",
       "          {\n",
       "            \" belongs\": -0.0026436392\n",
       "          },\n",
       "          {\n",
       "            \" to\": -0.018191135\n",
       "          },\n",
       "          {\n",
       "            \" each\": -0.14374322\n",
       "          },\n",
       "          {\n",
       "            \" of\": -0.65242213\n",
       "          },\n",
       "          {\n",
       "            \" of\": -0.0008370333\n",
       "          },\n",
       "          {\n",
       "            \" these\": -0.07059106\n",
       "          },\n",
       "          {\n",
       "            \" categories\": -0.0048575546\n",
       "          },\n",
       "          {\n",
       "            \" cannot\": -0.36430338\n",
       "          },\n",
       "          {\n",
       "            \" be\": -0.0046433923\n",
       "          },\n",
       "          {\n",
       "            \" determined\": -0.5605862\n",
       "          },\n",
       "          {\n",
       "            \" as\": -1.0550196\n",
       "          },\n",
       "          {\n",
       "            \" as\": -0.07327407\n",
       "          },\n",
       "          {\n",
       "            \" these\": -0.948769\n",
       "          },\n",
       "          {\n",
       "            \" is\": -0.23754029\n",
       "          },\n",
       "          {\n",
       "            \" not\": -0.5212061\n",
       "          },\n",
       "          {\n",
       "            \" a\": -0.19534627\n",
       "          },\n",
       "          {\n",
       "            \" straightforward\": -1.141444\n",
       "          },\n",
       "          {\n",
       "            \" classification\": -0.6942535\n",
       "          },\n",
       "          {\n",
       "            \" problem\": -0.3105902\n",
       "          },\n",
       "          {\n",
       "            \".\": -0.14003743\n",
       "          },\n",
       "          {\n",
       "            \" The\": -1.6482325\n",
       "          },\n",
       "          {\n",
       "            \" problems\": -0.30810335\n",
       "          },\n",
       "          {\n",
       "            \" involve\": -0.95644164\n",
       "          },\n",
       "          {\n",
       "            \" a\": -1.7241712\n",
       "          },\n",
       "          {\n",
       "            \"iating\": -2.1633925\n",
       "          },\n",
       "          {\n",
       "            \" of\": -0.0040128487\n",
       "          },\n",
       "          {\n",
       "            \" data\": -0.15083049\n",
       "          },\n",
       "          {\n",
       "            \" to\": -1.4659344\n",
       "          },\n",
       "          {\n",
       "            \"e\": -0.7955363\n",
       "          },\n",
       "          {\n",
       "            \" as\": -0.00027995434\n",
       "          },\n",
       "          {\n",
       "            \" text\": -0.7051607\n",
       "          },\n",
       "          {\n",
       "            \",\": -0.88473153\n",
       "          },\n",
       "          {\n",
       "            \")\": -0.64988846\n",
       "          },\n",
       "          {\n",
       "            \" to\": -0.8227687\n",
       "          },\n",
       "          {\n",
       "            \" be\": -0.22298871\n",
       "          },\n",
       "          {\n",
       "            \" able\": -1.2615155\n",
       "          },\n",
       "          {\n",
       "            \" in\": -0.80528486\n",
       "          },\n",
       "          {\n",
       "            \" classified\": -0.8308623\n",
       "          },\n",
       "          {\n",
       "            \" in\": -0.774565\n",
       "          },\n",
       "          {\n",
       "            \" order\": -0.0043438445\n",
       "          },\n",
       "          {\n",
       "            \" to\": -0.008558814\n",
       "          },\n",
       "          {\n",
       "            \" determine\": -0.6564563\n",
       "          },\n",
       "          {\n",
       "            \" the\": -0.37508067\n",
       "          },\n",
       "          {\n",
       "            \" probability\": -0.3235707\n",
       "          },\n",
       "          {\n",
       "            \" of\": -0.43169498\n",
       "          },\n",
       "          {\n",
       "            \" a\": -0.34355155\n",
       "          },\n",
       "          {\n",
       "            \" comment\": -0.23089445\n",
       "          },\n",
       "          {\n",
       "            \" belonging\": -0.0132514285\n",
       "          },\n",
       "          {\n",
       "            \" to\": -0.0139402235\n",
       "          },\n",
       "          {\n",
       "            \" a\": -0.5818733\n",
       "          },\n",
       "          {\n",
       "            \" certain\": -0.70303565\n",
       "          },\n",
       "          {\n",
       "            \" category\": -0.018185612\n",
       "          },\n",
       "          {\n",
       "            \".\": -0.0020094581\n",
       "          }\n",
       "        ]\n",
       "      },\n",
       "      \"text\": \"\\nThe probability a comment belongs to each one of these categories cannot be calculated, since it is not a simple classification problem. Classification problems require different types of data (such as text data) to be analyzed and evaluated in order to determine the probability of a comment belonging to a given category.\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1687714605,\n",
       "  \"id\": \"cmpl-7VNxFUYMRlq4J2xgA1kHu65T2XRD0\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 58,\n",
       "    \"prompt_tokens\": 242,\n",
       "    \"total_tokens\": 300\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_logprobs = response['choices'][0]['logprobs']['tokens']\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "80a1276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "    ## now grab the probs \n",
    "    token_logprobs = response['choices'][0]['logprobs']['tokens']\n",
    "### let's try combining all elements \n",
    "    l = ' '.join(token_logprobs)\n",
    "#l \n",
    "## now let's split and extract only numbers \n",
    "    temp = re.findall(r'\\d+', l)\n",
    "    res = list(map(int, temp))\n",
    "    ### now that we have a list of the three probs, let's store.\n",
    "    ## note. The first val is misrep, second somewhat misrep, and third not misrep \n",
    "    #rmp_df_sub['openai_is_misrep_prob'] = res[0]\n",
    "    #rmp_df_sub['openai_somewhat_misrep_prob'] = res[1]\n",
    "    #rmp_df_sub['openai_not_misrep_prob'] = res[2]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "371d6156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_id\n",
      "TOXICITY\n",
      "SEVERE_TOXICITY\n",
      "IDENTITY_ATTACK\n",
      "INSULT\n",
      "PROFANITY\n",
      "SEXUALLY_EXPLICIT\n",
      "THREAT\n",
      "FLIRTATION\n",
      "ATTACK_ON_AUTHOR\n",
      "INFLAMMATORY\n",
      "OBSCENE\n",
      "aggregate_outrage\n",
      "coded_toxic\n",
      "row\n",
      "quality_of_class\n",
      "difficulty_of_class\n",
      "class_code\n",
      "college\n",
      "prof_firstname\n",
      "prof_lastname\n",
      "comment\n",
      "out_misrep\n",
      "out_emo_lang\n",
      "out_ideo_extrem\n",
      "out_slip_slope\n",
      "out_insult\n",
      "out_mock_sarc\n",
      "out_threat\n",
      "pa_dress\n",
      "pa_appear\n",
      "pa_attit\n",
      "pa_interact\n",
      "pa_humor\n",
      "pa_other\n",
      "pb_sex\n",
      "pb_lgbtq\n",
      "pb_race\n",
      "pb_origin\n",
      "pb_nuero_div\n",
      "pb_phys_able\n",
      "pb_pol_affil\n",
      "complex\n",
      "constructive\n",
      "reflective\n",
      "outrage_agg\n",
      "personal_attack_agg\n",
      "prejudice_agg\n",
      "openai_is_misrep_prob\n",
      "openai_somewhat_misrep_prob\n",
      "openai_not_misrep_prob\n"
     ]
    }
   ],
   "source": [
    "for col in rmp_df_sub.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "de01c457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    342.0\n",
       "mean      50.0\n",
       "std        0.0\n",
       "min       50.0\n",
       "25%       50.0\n",
       "50%       50.0\n",
       "75%       50.0\n",
       "max       50.0\n",
       "Name: openai_somewhat_misrep_prob, dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmp_df_sub['openai_somewhat_misrep_prob'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "517319ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "342"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmp_df_sub.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d286496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
