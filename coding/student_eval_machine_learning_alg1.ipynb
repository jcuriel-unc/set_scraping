{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6f0e0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### First attempt to conduct machine learning on text data within the student evals \n",
    "## install pkgs \n",
    "import sys\n",
    "import os\n",
    "# !{sys.executable} -m pip install xgboost==1.7.5 # note: needed since it looks like anaconda installs an earlier version \n",
    "# of the package, which is not helpful. 1.7.5 allows for the categorical data of interest to be used. \n",
    "\n",
    "# !{sys.executable} -m pip install requests #; this code here can be used to install packages on anaconda/jupyter notebook \n",
    "### I believe the below should be installed by default \n",
    "import requests # web scraping \n",
    "from bs4 import BeautifulSoup # for web scraping \n",
    "import itertools # for efficient operation of loops \n",
    "import pandas as pd # necessary for reading in, creating, and manipulating data frames \n",
    "import csv ## for importing/exporting csvs \n",
    "import glob ## for finding files in path\n",
    "import re\n",
    "import numpy as np\n",
    "### THe ML packages \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn packages; for machine learning metrics and also text stuff (NLP)\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f05a0bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>quality_of_class</th>\n",
       "      <th>difficulty_of_class</th>\n",
       "      <th>class_code</th>\n",
       "      <th>college</th>\n",
       "      <th>prof_firstname</th>\n",
       "      <th>prof_lastname</th>\n",
       "      <th>comment</th>\n",
       "      <th>out_misrep</th>\n",
       "      <th>out_emo_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_origin</th>\n",
       "      <th>pb_nuero_div</th>\n",
       "      <th>pb_phys_able</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Only graded on 4 assignments (30% Midterm, 30%...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Final grade is only based on two exams, readin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLITSC1100</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Class was super easy. One reading quiz a week ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Lecture could be dry at times, but I still lik...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>was an excellent lecturer. Insightful, even h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC410</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>She's very fair. I got away with calling Karl ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Professor  is cool and all but her accent make...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Definitely not \"the greatest thing since slice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>She's not personal, almost to a harsh point. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>is an unpopular Sociology professor at OSU Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row  quality_of_class  difficulty_of_class   class_code  \\\n",
       "0       1               2.0                    4  POLITSC3500   \n",
       "1       2               3.0                    4  POLITSC3500   \n",
       "2       3               4.0                    1  POLITSC1100   \n",
       "3       4               4.0                    2  POLITSC3115   \n",
       "4       5               5.0                    3  POLITSC3115   \n",
       "...   ...               ...                  ...          ...   \n",
       "1095    4               4.0                    4       SOC410   \n",
       "1096    5               2.0                    4       SOC101   \n",
       "1097    6               1.0                    4       SOC101   \n",
       "1098    7               2.0                    4       SOC101   \n",
       "1099    8               2.0                    4       SOC101   \n",
       "\n",
       "                    college prof_firstname prof_lastname  \\\n",
       "0     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "1     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "2     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "3     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "4     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "...                     ...            ...           ...   \n",
       "1095  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1096  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1097  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1098  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1099  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "\n",
       "                                                comment  out_misrep  \\\n",
       "0     Only graded on 4 assignments (30% Midterm, 30%...           0   \n",
       "1     Final grade is only based on two exams, readin...           0   \n",
       "2     Class was super easy. One reading quiz a week ...           0   \n",
       "3     Lecture could be dry at times, but I still lik...           0   \n",
       "4      was an excellent lecturer. Insightful, even h...           0   \n",
       "...                                                 ...         ...   \n",
       "1095  She's very fair. I got away with calling Karl ...           0   \n",
       "1096  Professor  is cool and all but her accent make...           0   \n",
       "1097  Definitely not \"the greatest thing since slice...           0   \n",
       "1098  She's not personal, almost to a harsh point. T...           0   \n",
       "1099   is an unpopular Sociology professor at OSU Ma...           0   \n",
       "\n",
       "      out_emo_lang  ...  pb_origin  pb_nuero_div  pb_phys_able  pb_pol_affil  \\\n",
       "0                0  ...        0.0             0             0           0.0   \n",
       "1                0  ...        0.0             0             0           0.0   \n",
       "2                0  ...        0.0             0             0           0.0   \n",
       "3                0  ...        0.0             0             0           0.0   \n",
       "4                0  ...        0.0             0             0           0.0   \n",
       "...            ...  ...        ...           ...           ...           ...   \n",
       "1095             0  ...        0.0             0             0           0.0   \n",
       "1096             0  ...        0.0             0             0           0.0   \n",
       "1097             0  ...        0.0             0             0           0.0   \n",
       "1098             0  ...        0.0             0             0           0.0   \n",
       "1099             0  ...        0.0             0             0           0.0   \n",
       "\n",
       "      complex  constructive  reflective  outrage_agg  personal_attack_agg  \\\n",
       "0           0             0           0            0                    0   \n",
       "1           1             0           0            0                    0   \n",
       "2           0             0           0            0                    0   \n",
       "3           0             0           1            0                    0   \n",
       "4           0             0           0            0                    0   \n",
       "...       ...           ...         ...          ...                  ...   \n",
       "1095        0             0           0            0                    0   \n",
       "1096        0             0           0            0                    0   \n",
       "1097        0             0           0            1                    0   \n",
       "1098        0             0           0            1                    1   \n",
       "1099        0             0           0            1                    1   \n",
       "\n",
       "      prejudice_agg  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "...             ...  \n",
       "1095            0.0  \n",
       "1096            0.0  \n",
       "1097            0.0  \n",
       "1098            0.0  \n",
       "1099            0.0  \n",
       "\n",
       "[1100 rows x 34 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### read in the data \n",
    "rmp_df = pd.read_csv(\"text_cleaning_data/scored_rmp_data06212023.csv\")\n",
    "rmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8416bb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_31156\\3636061428.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  rmp_df['comment_edit'] = rmp_df['comment'].str.replace(pat, '') ## good, stop words removed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>quality_of_class</th>\n",
       "      <th>difficulty_of_class</th>\n",
       "      <th>class_code</th>\n",
       "      <th>college</th>\n",
       "      <th>prof_firstname</th>\n",
       "      <th>prof_lastname</th>\n",
       "      <th>comment</th>\n",
       "      <th>out_misrep</th>\n",
       "      <th>out_emo_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_nuero_div</th>\n",
       "      <th>pb_phys_able</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "      <th>comment_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Only graded on  assignments  Midterm  Final  R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Only graded   assignments  Midterm  Final  Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Final grade is only based on two exams reading...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Final grade   based  two exams reading quizzes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLITSC1100</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Class was super easy One reading quiz a week w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class  super easy One reading quiz  week   com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Lecture could be dry at times but I still like...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lecture could  dry  times  I still liked  clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>was an excellent lecturer Insightful even han...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>excellent lecturer Insightful even handed  wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC410</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Shes very fair I got away with calling Karl Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shes  fair I got away  calling Karl Marx  idio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Professor  is cool and all but her accent make...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Professor   cool     accent makes  hard  under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Definitely not the greatest thing since slice ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Definitely   greatest thing since slice bread ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Shes not personal almost to a harsh point The ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shes  personal almost   harsh point The class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>is an unpopular Sociology professor at OSU Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unpopular Sociology professor  OSU Marion She ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row  quality_of_class  difficulty_of_class   class_code  \\\n",
       "0       1               2.0                    4  POLITSC3500   \n",
       "1       2               3.0                    4  POLITSC3500   \n",
       "2       3               4.0                    1  POLITSC1100   \n",
       "3       4               4.0                    2  POLITSC3115   \n",
       "4       5               5.0                    3  POLITSC3115   \n",
       "...   ...               ...                  ...          ...   \n",
       "1095    4               4.0                    4       SOC410   \n",
       "1096    5               2.0                    4       SOC101   \n",
       "1097    6               1.0                    4       SOC101   \n",
       "1098    7               2.0                    4       SOC101   \n",
       "1099    8               2.0                    4       SOC101   \n",
       "\n",
       "                    college prof_firstname prof_lastname  \\\n",
       "0     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "1     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "2     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "3     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "4     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "...                     ...            ...           ...   \n",
       "1095  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1096  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1097  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1098  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1099  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "\n",
       "                                                comment  out_misrep  \\\n",
       "0     Only graded on  assignments  Midterm  Final  R...           0   \n",
       "1     Final grade is only based on two exams reading...           0   \n",
       "2     Class was super easy One reading quiz a week w...           0   \n",
       "3     Lecture could be dry at times but I still like...           0   \n",
       "4      was an excellent lecturer Insightful even han...           0   \n",
       "...                                                 ...         ...   \n",
       "1095  Shes very fair I got away with calling Karl Ma...           0   \n",
       "1096  Professor  is cool and all but her accent make...           0   \n",
       "1097  Definitely not the greatest thing since slice ...           0   \n",
       "1098  Shes not personal almost to a harsh point The ...           0   \n",
       "1099   is an unpopular Sociology professor at OSU Ma...           0   \n",
       "\n",
       "      out_emo_lang  ...  pb_nuero_div  pb_phys_able  pb_pol_affil  complex  \\\n",
       "0                0  ...             0             0           0.0        0   \n",
       "1                0  ...             0             0           0.0        1   \n",
       "2                0  ...             0             0           0.0        0   \n",
       "3                0  ...             0             0           0.0        0   \n",
       "4                0  ...             0             0           0.0        0   \n",
       "...            ...  ...           ...           ...           ...      ...   \n",
       "1095             0  ...             0             0           0.0        0   \n",
       "1096             0  ...             0             0           0.0        0   \n",
       "1097             0  ...             0             0           0.0        0   \n",
       "1098             0  ...             0             0           0.0        0   \n",
       "1099             0  ...             0             0           0.0        0   \n",
       "\n",
       "      constructive  reflective  outrage_agg  personal_attack_agg  \\\n",
       "0                0           0            0                    0   \n",
       "1                0           0            0                    0   \n",
       "2                0           0            0                    0   \n",
       "3                0           1            0                    0   \n",
       "4                0           0            0                    0   \n",
       "...            ...         ...          ...                  ...   \n",
       "1095             0           0            0                    0   \n",
       "1096             0           0            0                    0   \n",
       "1097             0           0            1                    0   \n",
       "1098             0           0            1                    1   \n",
       "1099             0           0            1                    1   \n",
       "\n",
       "      prejudice_agg                                       comment_edit  \n",
       "0               0.0  Only graded   assignments  Midterm  Final  Rea...  \n",
       "1               0.0  Final grade   based  two exams reading quizzes...  \n",
       "2               0.0  Class  super easy One reading quiz  week   com...  \n",
       "3               0.0  Lecture could  dry  times  I still liked  clas...  \n",
       "4               0.0  excellent lecturer Insightful even handed  wil...  \n",
       "...             ...                                                ...  \n",
       "1095            0.0  Shes  fair I got away  calling Karl Marx  idio...  \n",
       "1096            0.0  Professor   cool     accent makes  hard  under...  \n",
       "1097            0.0  Definitely   greatest thing since slice bread ...  \n",
       "1098            0.0  Shes  personal almost   harsh point The class ...  \n",
       "1099            0.0  unpopular Sociology professor  OSU Marion She ...  \n",
       "\n",
       "[1100 rows x 35 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now clean the text \n",
    "regex = r\"[\\\"#\\$%&\\'\\(\\)\\*\\+,-\\./:;<=>\\?@\\[\\\\\\]\\^_`{\\|}~]\" # I removed ! from the beginning \n",
    "\n",
    "rmp_df['comment'] = rmp_df['comment'].replace(to_replace =regex, value = '', regex = True)\n",
    "rmp_df['comment'] = rmp_df['comment'].replace(to_replace =\"\\d+\", value = '', regex = True)\n",
    "\n",
    "#rmp_df['comment'] = re.sub(regex, '', str(rmp_df['comment']).strip() )\n",
    "#rmp_df['comment'] =  re.sub(\"\\d+\", \" \", str(rmp_df['comment'] ))\n",
    "\n",
    "## reading in the stopwords \n",
    "stop_words = stopwords.words('english') # creates a list of English stop words\n",
    "# wnl = WordNetLemmatizer() # I used lemmatizing instead of stemming\n",
    " ## looks like it worked now \n",
    "\n",
    "pat = '|'.join([r'\\b{}\\b'.format(w) for w in stop_words])\n",
    "\n",
    "rmp_df['comment_edit'] = rmp_df['comment'].str.replace(pat, '') ## good, stop words removed \n",
    "rmp_df['comment_edit'] = rmp_df['comment_edit'].str.strip()\n",
    "### now apply stemming\n",
    "\n",
    "rmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e335158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmp_df['comment_edit'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "240003de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>quality_of_class</th>\n",
       "      <th>difficulty_of_class</th>\n",
       "      <th>class_code</th>\n",
       "      <th>college</th>\n",
       "      <th>prof_firstname</th>\n",
       "      <th>prof_lastname</th>\n",
       "      <th>comment</th>\n",
       "      <th>out_misrep</th>\n",
       "      <th>out_emo_lang</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_nuero_div</th>\n",
       "      <th>pb_phys_able</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "      <th>comment_edit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Only graded on  assignments  Midterm  Final  R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Only graded   assignments  Midterm  Final  Rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Final grade is only based on two exams reading...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Final grade   based  two exams reading quizzes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLITSC1100</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Class was super easy One reading quiz a week w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Class  super easy One reading quiz  week   com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Lecture could be dry at times but I still like...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lecture could  dry  times  I still liked  clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>was an excellent lecturer Insightful even han...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>excellent lecturer Insightful even handed  wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC410</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Shes very fair I got away with calling Karl Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shes  fair I got away  calling Karl Marx  idio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Professor  is cool and all but her accent make...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Professor   cool     accent makes  hard  under...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Definitely not the greatest thing since slice ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Definitely   greatest thing since slice bread ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Shes not personal almost to a harsh point The ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Shes  personal almost   harsh point The class ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>is an unpopular Sociology professor at OSU Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unpopular Sociology professor  OSU Marion She ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row  quality_of_class  difficulty_of_class   class_code  \\\n",
       "0       1               2.0                    4  POLITSC3500   \n",
       "1       2               3.0                    4  POLITSC3500   \n",
       "2       3               4.0                    1  POLITSC1100   \n",
       "3       4               4.0                    2  POLITSC3115   \n",
       "4       5               5.0                    3  POLITSC3115   \n",
       "...   ...               ...                  ...          ...   \n",
       "1095    4               4.0                    4       SOC410   \n",
       "1096    5               2.0                    4       SOC101   \n",
       "1097    6               1.0                    4       SOC101   \n",
       "1098    7               2.0                    4       SOC101   \n",
       "1099    8               2.0                    4       SOC101   \n",
       "\n",
       "                    college prof_firstname prof_lastname  \\\n",
       "0     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "1     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "2     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "3     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "4     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "...                     ...            ...           ...   \n",
       "1095  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1096  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1097  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1098  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1099  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "\n",
       "                                                comment  out_misrep  \\\n",
       "0     Only graded on  assignments  Midterm  Final  R...           0   \n",
       "1     Final grade is only based on two exams reading...           0   \n",
       "2     Class was super easy One reading quiz a week w...           0   \n",
       "3     Lecture could be dry at times but I still like...           0   \n",
       "4      was an excellent lecturer Insightful even han...           0   \n",
       "...                                                 ...         ...   \n",
       "1095  Shes very fair I got away with calling Karl Ma...           0   \n",
       "1096  Professor  is cool and all but her accent make...           0   \n",
       "1097  Definitely not the greatest thing since slice ...           0   \n",
       "1098  Shes not personal almost to a harsh point The ...           0   \n",
       "1099   is an unpopular Sociology professor at OSU Ma...           0   \n",
       "\n",
       "      out_emo_lang  ...  pb_nuero_div  pb_phys_able  pb_pol_affil  complex  \\\n",
       "0                0  ...             0             0           0.0        0   \n",
       "1                0  ...             0             0           0.0        1   \n",
       "2                0  ...             0             0           0.0        0   \n",
       "3                0  ...             0             0           0.0        0   \n",
       "4                0  ...             0             0           0.0        0   \n",
       "...            ...  ...           ...           ...           ...      ...   \n",
       "1095             0  ...             0             0           0.0        0   \n",
       "1096             0  ...             0             0           0.0        0   \n",
       "1097             0  ...             0             0           0.0        0   \n",
       "1098             0  ...             0             0           0.0        0   \n",
       "1099             0  ...             0             0           0.0        0   \n",
       "\n",
       "      constructive  reflective  outrage_agg  personal_attack_agg  \\\n",
       "0                0           0            0                    0   \n",
       "1                0           0            0                    0   \n",
       "2                0           0            0                    0   \n",
       "3                0           1            0                    0   \n",
       "4                0           0            0                    0   \n",
       "...            ...         ...          ...                  ...   \n",
       "1095             0           0            0                    0   \n",
       "1096             0           0            0                    0   \n",
       "1097             0           0            1                    0   \n",
       "1098             0           0            1                    1   \n",
       "1099             0           0            1                    1   \n",
       "\n",
       "      prejudice_agg                                       comment_edit  \n",
       "0               0.0  Only graded   assignments  Midterm  Final  Rea...  \n",
       "1               0.0  Final grade   based  two exams reading quizzes...  \n",
       "2               0.0  Class  super easy One reading quiz  week   com...  \n",
       "3               0.0  Lecture could  dry  times  I still liked  clas...  \n",
       "4               0.0  excellent lecturer Insightful even handed  wil...  \n",
       "...             ...                                                ...  \n",
       "1095            0.0  Shes  fair I got away  calling Karl Marx  idio...  \n",
       "1096            0.0  Professor   cool     accent makes  hard  under...  \n",
       "1097            0.0  Definitely   greatest thing since slice bread ...  \n",
       "1098            0.0  Shes  personal almost   harsh point The class ...  \n",
       "1099            0.0  unpopular Sociology professor  OSU Marion She ...  \n",
       "\n",
       "[1100 rows x 35 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now apply stemming to the comments \n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "#rmp_df_sub = rmp_df.iloc[0:2,:]\n",
    "#for w in rmp_df_sub.comment_edit: \n",
    "#    print(w, \" : \", ps.stem(w)) \n",
    "#rmp_df['stem'] = rmp_df.comment_edit.apply(ps.stem)\n",
    "    \n",
    "rmp_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691b7617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a3d37d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### attempt to lemmatize, thereby shortening words \n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "## lematize here \n",
    "text_lemmatized = rmp_df.comment_edit.apply(lemmatize_text)\n",
    "\n",
    "#rmp_df['comment_edit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d10ac460",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmp_df.assign(text_lemmatized=text_lemmatized)\n",
    "rmp_df['text_lemmatized'] = pd.Series(text_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cdd90e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       [Only, graded, assignment, Midterm, Final, Rea...\n",
      "1       [Final, grade, based, two, exam, reading, quiz...\n",
      "2       [Class, super, easy, One, reading, quiz, week,...\n",
      "3       [Lecture, could, dry, time, I, still, liked, c...\n",
      "4       [excellent, lecturer, Insightful, even, handed...\n",
      "                              ...                        \n",
      "1095    [Shes, fair, I, got, away, calling, Karl, Marx...\n",
      "1096    [Professor, cool, accent, make, hard, understa...\n",
      "1097    [Definitely, greatest, thing, since, slice, br...\n",
      "1098    [Shes, personal, almost, harsh, point, The, cl...\n",
      "1099    [unpopular, Sociology, professor, OSU, Marion,...\n",
      "Name: text_lemmatized, Length: 1100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(rmp_df['text_lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "14db289f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968    [Awesome, professor, There, test, easy, paper,...\n",
       "201    [Very, sweet, woman, Extremely, helpful, Decen...\n",
       "455    [Dr, great, professor, She, really, care, stud...\n",
       "9      [Aces, clearly, love, information, teaching, c...\n",
       "52     [Prof, good, lecturer, The, class, typical, po...\n",
       "                             ...                        \n",
       "778    [He, seemed, friendlyeager, help, student, ter...\n",
       "78     [great, guy, best, professor, department, I, t...\n",
       "814    [Makes, class, interesting, seems, knowledgabl...\n",
       "71     [I, loved, class, They, enthusiastic, much, ex...\n",
       "700    [Whoever, say, bad, wrong, Dr, really, good, t...\n",
       "Name: text_lemmatized, Length: 275, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Let's move on for now and test these later \n",
    "## Now we will want to decrease size of data. For now, let's just go with the misrep column\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#rmp_df_sub = rmp_df.loc[:,'comment_edit','out_misrep']\n",
    "\n",
    "### now let's split up the data into train and test sets \n",
    "# Split the data; follows the same syntax as box 6 via the commas \n",
    "X_train, X_test, y_train, y_test = train_test_split(rmp_df['text_lemmatized'], rmp_df['out_misrep'], random_state=1337,\n",
    "                                                   stratify=rmp_df['out_misrep'], test_size=0.25)\n",
    "\n",
    "# vectorizing the sentences\n",
    "#cv = CountVectorizer(binary = True) # implies that it indicates whether the word is present or not.\n",
    "#cv.fit(train['review']) # find all the unique words from the training set\n",
    "#train_x = cv.transform(train['review'])\n",
    "#test_x = cv.transform(test['review'])\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dacc47a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276     ['The', 'assignment', 'two', 'group', 'project...\n",
       "1032    ['She', 'sweet', 'make', 'class', 'interesting...\n",
       "782     ['Shes', 'sweet', 'person', 'lecture', 'drag',...\n",
       "3       ['Lecture', 'could', 'dry', 'time', 'I', 'stil...\n",
       "156     ['My', 'favorite', 'professor', 'EVER', 'I', '...\n",
       "                              ...                        \n",
       "277     ['The', 'lecture', 'pretty', 'boring', 'Dr', '...\n",
       "235     ['Dr', 'amazing', 'professor!', 'She', 'clear'...\n",
       "494     ['She', 'one', 'favorite', 'teacher', 'tell', ...\n",
       "920     ['A', 'mess', 'prof', 'direction', 'lecture', ...\n",
       "165     ['Dr', 'amazing', 'professor!!', 'I', 'took', ...\n",
       "Name: text_lemmatized, Length: 825, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lemmatized_all = X_train.astype(str)\n",
    "text_lemmatized_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5f0b579c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<825x15041 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19782 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### let's try to apply the above to the data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# link to cmd syntax: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "X_train = X_train.astype(str)\n",
    "def tokens(x): return x.split(',')\n",
    "tfidf_vect= TfidfVectorizer( tokenizer=tokens \n",
    "                            ,use_idf=True\n",
    "                            , smooth_idf=True\n",
    "                            , min_df = 1\n",
    "                            , stop_words = 'english',\n",
    "                            #, max_features = 10\n",
    "                            sublinear_tf=False,\n",
    "                           ngram_range=(2,2),\n",
    "                           lowercase=False)\n",
    "\n",
    "tf_idf_matrix = pd.DataFrame(\n",
    "    tfidf_vect.fit_transform(X_train).toarray(), \n",
    "    columns=tfidf_vect.get_feature_names()\n",
    ")\n",
    "\n",
    "Xtrain_mat=tfidf_vect.fit_transform(X_train)\n",
    "Xtrain_mat ### good, this is what we want "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64db9c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'!!'  'He'</th>\n",
       "      <th>'!!'  'Ive'</th>\n",
       "      <th>'!!'  'shes'</th>\n",
       "      <th>'!'  'Class'</th>\n",
       "      <th>'!'  'Had'</th>\n",
       "      <th>'!'  'Hell'</th>\n",
       "      <th>'!'  'I'</th>\n",
       "      <th>'!'  'Passionate'</th>\n",
       "      <th>'!'  'She'</th>\n",
       "      <th>'!'  'The'</th>\n",
       "      <th>...</th>\n",
       "      <th>['shes'  'boring'</th>\n",
       "      <th>['shouldnt'  'teaching'</th>\n",
       "      <th>['smart'  'Pay'</th>\n",
       "      <th>['smart'  'guy'</th>\n",
       "      <th>['suck'  'get'</th>\n",
       "      <th>['sweet'  'caring'</th>\n",
       "      <th>['take'  'next'</th>\n",
       "      <th>['talk'  'way'</th>\n",
       "      <th>['test'  'pop'</th>\n",
       "      <th>['took'  'class'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>825 rows × 15041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      '!!'  'He'   '!!'  'Ive'   '!!'  'shes'   '!'  'Class'   '!'  'Had'  \\\n",
       "0            0.0           0.0            0.0            0.0          0.0   \n",
       "1            0.0           0.0            0.0            0.0          0.0   \n",
       "2            0.0           0.0            0.0            0.0          0.0   \n",
       "3            0.0           0.0            0.0            0.0          0.0   \n",
       "4            0.0           0.0            0.0            0.0          0.0   \n",
       "..           ...           ...            ...            ...          ...   \n",
       "820          0.0           0.0            0.0            0.0          0.0   \n",
       "821          0.0           0.0            0.0            0.0          0.0   \n",
       "822          0.0           0.0            0.0            0.0          0.0   \n",
       "823          0.0           0.0            0.0            0.0          0.0   \n",
       "824          0.0           0.0            0.0            0.0          0.0   \n",
       "\n",
       "      '!'  'Hell'   '!'  'I'   '!'  'Passionate'   '!'  'She'   '!'  'The'  \\\n",
       "0             0.0        0.0                 0.0          0.0          0.0   \n",
       "1             0.0        0.0                 0.0          0.0          0.0   \n",
       "2             0.0        0.0                 0.0          0.0          0.0   \n",
       "3             0.0        0.0                 0.0          0.0          0.0   \n",
       "4             0.0        0.0                 0.0          0.0          0.0   \n",
       "..            ...        ...                 ...          ...          ...   \n",
       "820           0.0        0.0                 0.0          0.0          0.0   \n",
       "821           0.0        0.0                 0.0          0.0          0.0   \n",
       "822           0.0        0.0                 0.0          0.0          0.0   \n",
       "823           0.0        0.0                 0.0          0.0          0.0   \n",
       "824           0.0        0.0                 0.0          0.0          0.0   \n",
       "\n",
       "     ...  ['shes'  'boring'  ['shouldnt'  'teaching'  ['smart'  'Pay'  \\\n",
       "0    ...                0.0                      0.0              0.0   \n",
       "1    ...                0.0                      0.0              0.0   \n",
       "2    ...                0.0                      0.0              0.0   \n",
       "3    ...                0.0                      0.0              0.0   \n",
       "4    ...                0.0                      0.0              0.0   \n",
       "..   ...                ...                      ...              ...   \n",
       "820  ...                0.0                      0.0              0.0   \n",
       "821  ...                0.0                      0.0              0.0   \n",
       "822  ...                0.0                      0.0              0.0   \n",
       "823  ...                0.0                      0.0              0.0   \n",
       "824  ...                0.0                      0.0              0.0   \n",
       "\n",
       "     ['smart'  'guy'  ['suck'  'get'  ['sweet'  'caring'  ['take'  'next'  \\\n",
       "0                0.0             0.0                 0.0              0.0   \n",
       "1                0.0             0.0                 0.0              0.0   \n",
       "2                0.0             0.0                 0.0              0.0   \n",
       "3                0.0             0.0                 0.0              0.0   \n",
       "4                0.0             0.0                 0.0              0.0   \n",
       "..               ...             ...                 ...              ...   \n",
       "820              0.0             0.0                 0.0              0.0   \n",
       "821              0.0             0.0                 0.0              0.0   \n",
       "822              0.0             0.0                 0.0              0.0   \n",
       "823              0.0             0.0                 0.0              0.0   \n",
       "824              0.0             0.0                 0.0              0.0   \n",
       "\n",
       "     ['talk'  'way'  ['test'  'pop'  ['took'  'class'  \n",
       "0               0.0             0.0               0.0  \n",
       "1               0.0             0.0               0.0  \n",
       "2               0.0             0.0               0.0  \n",
       "3               0.0             0.0               0.0  \n",
       "4               0.0             0.0               0.0  \n",
       "..              ...             ...               ...  \n",
       "820             0.0             0.0               0.0  \n",
       "821             0.0             0.0               0.0  \n",
       "822             0.0             0.0               0.0  \n",
       "823             0.0             0.0               0.0  \n",
       "824             0.0             0.0               0.0  \n",
       "\n",
       "[825 rows x 15041 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix ### this is a visual representation of what's being produced. Note that it is only for the first row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "34592e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<275x5907 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6852 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now do the same for the test set \n",
    "X_test = X_test.astype(str)\n",
    "Xtest_mat=tfidf_vect.fit_transform(X_test)\n",
    "Xtest_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b02fb7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in ordinal encorder \n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "### try to do a grid search \n",
    "\n",
    "xgb_train = xgb.DMatrix(Xtrain_mat, y_train, enable_categorical=True)\n",
    "xgb_test = xgb.DMatrix(Xtest_mat, y_test, enable_categorical=True)\n",
    "\n",
    "\n",
    "#grid_search = GridSearchCV(estimator = pipe, param_grid = param_grid, \n",
    "#                          cv = 3, n_jobs = 1, verbose = 0, return_train_score=True)\n",
    "\n",
    "#hyperparameter fitting ; where it did not work for me ; also broke down here \n",
    "#grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "93cad167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Parameters of the Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "## set parameters \n",
    "params = {\"objective\": \"multi:softprob\", \"tree_method\": \"gpu_hist\", \"num_class\": 3}\n",
    "n = 1000\n",
    "\n",
    "results = xgb.cv(\n",
    "   params, xgb_train,\n",
    "   num_boost_round=n,\n",
    "   nfold=3,\n",
    "   metrics=[\"mlogloss\", \"auc\", \"merror\"], ## here we are telling to look at three metrics, which are \n",
    "    # multi-class log loss, area under the ROC curve, and multi-class classification error\n",
    ") # note that the auc is the flase positive rate (x axis) plotted against the true positive rate (y-axis). Closer to 1, teh \n",
    "# better, with 0 being garbage \n",
    "\n",
    "#results.keys() # keys() method returns a list of all the keys in a dictionary, and what can be analyzed. Let's take a look\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ec06535c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5493390209430675"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['test-auc-mean'].max()# at 0.57; not ideal, but not the worst either. Better than random \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "015d0274",
   "metadata": {},
   "outputs": [],
   "source": [
    "misrep_model =xgb.train(params, xgb_train, num_boost_round = n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ea89ba76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [7.9648620e-01, 1.9081961e-01, 1.2694186e-02],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.9005437e-01, 6.3829627e-03, 3.5626644e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.7138691e-01, 2.1159230e-02, 7.4538966e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6775705e-01, 2.2987934e-02, 9.2550712e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.5576435e-01, 3.6901593e-02, 7.3340172e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [3.6643034e-01, 4.7887382e-01, 1.5469584e-01],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.7926348e-01, 1.5673393e-02, 5.0631477e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.9971491e-01, 1.8008292e-04, 1.0494511e-04],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.8941600e-01, 4.5899502e-03, 5.9940326e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6316761e-01, 2.2878917e-02, 1.3953494e-02],\n",
       "       [8.1327850e-01, 1.4113057e-01, 4.5590937e-02],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6775705e-01, 2.2987934e-02, 9.2550712e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.7707772e-01, 1.7325426e-02, 5.5968217e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6425790e-01, 2.8342912e-02, 7.3991925e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [7.7692312e-01, 1.6198622e-01, 6.1090700e-02],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.7138751e-01, 2.1158604e-02, 7.4539008e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03],\n",
       "       [9.6953034e-01, 2.3030056e-02, 7.4396497e-03]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###lets see fit \n",
    "#misrep_model.fit(xgb_train, xgb_test)\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#model = GridSearchCV(estimator = misrep_model,param_grid = xgb_test)\n",
    "\n",
    "y_test_pred = misrep_model.predict(xgb_test)\n",
    "y_test_pred # seems like this defaults to a naive dist when not paired with data it recognizes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9272ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save model \n",
    "# save to JSON\n",
    "misrep_model.save_model(\"model_06222023.json\")\n",
    "\n",
    "## to load in: \n",
    "misrep_model = xgb.Booster()\n",
    "misrep_model.load_model(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aab3e0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9572092e-01, 3.3867841e-03, 8.9231879e-04],\n",
       "       [9.9675626e-01, 1.4976424e-03, 1.7460856e-03],\n",
       "       [9.9279273e-01, 5.7049468e-03, 1.5022800e-03],\n",
       "       ...,\n",
       "       [9.6849906e-01, 2.8263498e-02, 3.2375008e-03],\n",
       "       [9.8419487e-01, 1.4423719e-02, 1.3813366e-03],\n",
       "       [9.0871793e-01, 8.8724770e-02, 2.5573066e-03]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### let's apply to our test data \n",
    "y_pred = misrep_model.predict(xgb_test)\n",
    "y_pred # this returns an array, which is 3 cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2822ac3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_misrep</th>\n",
       "      <th>somewhat_misrep</th>\n",
       "      <th>very_misrep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995721</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996756</td>\n",
       "      <td>0.001498</td>\n",
       "      <td>0.001746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.992793</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.001502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973856</td>\n",
       "      <td>0.011509</td>\n",
       "      <td>0.014635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.983300</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.001901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.983300</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.001901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.986898</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>0.001862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.996881</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995054</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.003062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.997689</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.000494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_misrep  somewhat_misrep  very_misrep\n",
       "0    0.995721         0.003387     0.000892\n",
       "1    0.996756         0.001498     0.001746\n",
       "2    0.992793         0.005705     0.001502\n",
       "3    0.973856         0.011509     0.014635\n",
       "4    0.983300         0.014799     0.001901\n",
       "5    0.983300         0.014799     0.001901\n",
       "6    0.986898         0.011239     0.001862\n",
       "7    0.996881         0.001522     0.001597\n",
       "8    0.995054         0.001883     0.003062\n",
       "9    0.997689         0.001817     0.000494"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred, columns=['not_misrep','somewhat_misrep','very_misrep'])\n",
    "y_pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c0714f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18419794738292694"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df['not_misrep'].min() # lowest is still 54 %; means most are not considered misrep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8da88436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x26cab87c1f0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### let's predict onto the total data set \n",
    "x_final = rmp_df['text_lemmatized']\n",
    "\n",
    "### clean type \n",
    "x_final = x_final.astype(str)\n",
    "x_final_mat=tfidf_vect.fit_transform(x_final)\n",
    "\n",
    "## check \n",
    "\n",
    "\n",
    "x_final_mat = xgb.DMatrix(x_final_mat, enable_categorical=True)\n",
    "x_final_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1eb6778e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.2476314e-01, 1.5898839e-02, 5.9338052e-02],\n",
       "       [9.0144825e-01, 9.4556957e-02, 3.9948090e-03],\n",
       "       [9.9688524e-01, 2.5627632e-03, 5.5202644e-04],\n",
       "       ...,\n",
       "       [9.1458035e-01, 7.5135946e-02, 1.0283697e-02],\n",
       "       [9.5847327e-01, 1.9467477e-02, 2.2059243e-02],\n",
       "       [9.9813062e-01, 7.4268936e-04, 1.1266695e-03]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now let's try to predict \n",
    "post_model_pred = misrep_model.predict(x_final_mat)\n",
    "post_model_pred ## good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b38d12db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>not_misrep</th>\n",
       "      <th>somewhat_misrep</th>\n",
       "      <th>very_misrep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.924763</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.059338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.901448</td>\n",
       "      <td>0.094557</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996198</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.989664</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.008490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.924763</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.059338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.996572</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.002087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.948045</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>0.003318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998607</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.005857</td>\n",
       "      <td>0.001663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   not_misrep  somewhat_misrep  very_misrep\n",
       "0    0.924763         0.015899     0.059338\n",
       "1    0.901448         0.094557     0.003995\n",
       "2    0.996885         0.002563     0.000552\n",
       "3    0.996198         0.001970     0.001832\n",
       "4    0.989664         0.001846     0.008490\n",
       "5    0.924763         0.015899     0.059338\n",
       "6    0.996572         0.001341     0.002087\n",
       "7    0.948045         0.048637     0.003318\n",
       "8    0.998607         0.000904     0.000489\n",
       "9    0.992481         0.005857     0.001663"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now create df \n",
    "post_model_pred_df = pd.DataFrame(post_model_pred, columns=['not_misrep','somewhat_misrep','very_misrep'])\n",
    "post_model_pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d491529b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality_of_class</th>\n",
       "      <th>difficulty_of_class</th>\n",
       "      <th>class_code</th>\n",
       "      <th>college</th>\n",
       "      <th>prof_firstname</th>\n",
       "      <th>prof_lastname</th>\n",
       "      <th>comment</th>\n",
       "      <th>out_misrep</th>\n",
       "      <th>not_misrep</th>\n",
       "      <th>somewhat_misrep</th>\n",
       "      <th>very_misrep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Only graded on  assignments  Midterm  Final  R...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.924763</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.059338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>POLITSC3500</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Final grade is only based on two exams reading...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.901448</td>\n",
       "      <td>0.094557</td>\n",
       "      <td>0.003995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>POLITSC1100</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Class was super easy One reading quiz a week w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996885</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.000552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Lecture could be dry at times but I still like...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996198</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.001832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>POLITSC3115</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>ALEX</td>\n",
       "      <td>ACS</td>\n",
       "      <td>Alex was an excellent lecturer Insightful even...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.989664</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.008490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC410</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Shes very fair I got away with calling Karl Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.990735</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.004516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Professor klochko is cool and all but her acce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.918948</td>\n",
       "      <td>0.077825</td>\n",
       "      <td>0.003227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Definitely not the greatest thing since slice ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.914580</td>\n",
       "      <td>0.075136</td>\n",
       "      <td>0.010284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Shes not personal almost to a harsh point The ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.958473</td>\n",
       "      <td>0.019467</td>\n",
       "      <td>0.022059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>SOC101</td>\n",
       "      <td>OHIO STATE UNIVERSITY</td>\n",
       "      <td>MARIANNA</td>\n",
       "      <td>KLOCHKO</td>\n",
       "      <td>Klochko is an unpopular Sociology professor at...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998131</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality_of_class  difficulty_of_class   class_code  \\\n",
       "0                  2.0                    4  POLITSC3500   \n",
       "1                  3.0                    4  POLITSC3500   \n",
       "2                  4.0                    1  POLITSC1100   \n",
       "3                  4.0                    2  POLITSC3115   \n",
       "4                  5.0                    3  POLITSC3115   \n",
       "...                ...                  ...          ...   \n",
       "1095               4.0                    4       SOC410   \n",
       "1096               2.0                    4       SOC101   \n",
       "1097               1.0                    4       SOC101   \n",
       "1098               2.0                    4       SOC101   \n",
       "1099               2.0                    4       SOC101   \n",
       "\n",
       "                    college prof_firstname prof_lastname  \\\n",
       "0     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "1     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "2     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "3     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "4     OHIO STATE UNIVERSITY           ALEX           ACS   \n",
       "...                     ...            ...           ...   \n",
       "1095  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1096  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1097  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1098  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "1099  OHIO STATE UNIVERSITY       MARIANNA       KLOCHKO   \n",
       "\n",
       "                                                comment  out_misrep  \\\n",
       "0     Only graded on  assignments  Midterm  Final  R...           0   \n",
       "1     Final grade is only based on two exams reading...           0   \n",
       "2     Class was super easy One reading quiz a week w...           0   \n",
       "3     Lecture could be dry at times but I still like...           0   \n",
       "4     Alex was an excellent lecturer Insightful even...           0   \n",
       "...                                                 ...         ...   \n",
       "1095  Shes very fair I got away with calling Karl Ma...           0   \n",
       "1096  Professor klochko is cool and all but her acce...           0   \n",
       "1097  Definitely not the greatest thing since slice ...           0   \n",
       "1098  Shes not personal almost to a harsh point The ...           0   \n",
       "1099  Klochko is an unpopular Sociology professor at...           0   \n",
       "\n",
       "      not_misrep  somewhat_misrep  very_misrep  \n",
       "0       0.924763         0.015899     0.059338  \n",
       "1       0.901448         0.094557     0.003995  \n",
       "2       0.996885         0.002563     0.000552  \n",
       "3       0.996198         0.001970     0.001832  \n",
       "4       0.989664         0.001846     0.008490  \n",
       "...          ...              ...          ...  \n",
       "1095    0.990735         0.004749     0.004516  \n",
       "1096    0.918948         0.077825     0.003227  \n",
       "1097    0.914580         0.075136     0.010284  \n",
       "1098    0.958473         0.019467     0.022059  \n",
       "1099    0.998131         0.000743     0.001127  \n",
       "\n",
       "[1100 rows x 11 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### lets combine the data frame and take a look \n",
    "rmp_misrep = rmp_df.iloc[:,1:9]\n",
    "rmp_misrep2 =pd.concat([rmp_misrep, post_model_pred_df], axis=1)\n",
    "rmp_misrep2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fe1ccfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write out csv \n",
    "rmp_misrep2.to_csv(\"output/misrep_predicted_06212023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1601a4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### convert pred probs to class \n",
    "idx = np.argmax(y_pred, axis=-1)\n",
    "y_pred = np.zeros( y_pred.shape )\n",
    "y_pred[ np.arange(y_pred.shape[0]), idx] = 1\n",
    "\n",
    "y_pred ## seems to have worked; now we just need to get to long "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4af8f0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create data frame \n",
    "\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=['not_misrep','somewhat_misrep','very_misrep'])\n",
    "### now create a column based on max \n",
    "y_pred_df['label'] = np.where(y_pred_df['not_misrep'] == 1, 0, 1)\n",
    "y_pred_df.loc[y_pred_df.somewhat_misrep==1, 'label'] == 1\n",
    "y_pred_df.loc[y_pred_df.very_misrep==1, 'label'] == 2\n",
    "y_pred_df['label'].unique() ## none of these are above 0. This implies issues wrt too many non misrep comments. This might \n",
    "# not be too big of an issue, assuming that we can get all of these dimensions summed up \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5ecaf5fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11280\\3187789820.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mxgb_test_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_test_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# supposed to be  94.83%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1121\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \"\"\"\n\u001b[1;32m-> 1123\u001b[1;33m     return fbeta_score(\n\u001b[0m\u001b[0;32m   1124\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \"\"\"\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(\n\u001b[0m\u001b[0;32m   1262\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1544\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[1;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"average has to be one of \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "### let's look at accuracy \n",
    "xgb_test_labels = []\n",
    "for rating in y_test:\n",
    "    if rating == 0:\n",
    "        xgb_test_labels.append(0)\n",
    "    elif rating == 2:\n",
    "        xgb_test_labels.append(2)\n",
    "    else:\n",
    "        xgb_test_labels.append(1)\n",
    "f1_score(xgb_test_labels, y_pred) # supposed to be  94.83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa9d49f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.5794606e-01, 3.6805231e-02, 5.2486709e-03],\n",
       "       [9.9901891e-01, 6.8283116e-04, 2.9829287e-04],\n",
       "       [9.5847327e-01, 1.9467477e-02, 2.2059243e-02],\n",
       "       ...,\n",
       "       [9.8856038e-01, 4.9981573e-03, 6.4414935e-03],\n",
       "       [9.7794914e-01, 2.0888600e-02, 1.1622668e-03],\n",
       "       [9.9745852e-01, 1.8508084e-03, 6.9073279e-04]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0b1092a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11280\\1553777003.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ddd01217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.051551352248216366"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['test-auc-mean'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "95a1d79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import accuracy_score   \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.datasets import load_iris  \n",
    "  \n",
    "# Loading the dataset  \n",
    "X, Y = load_iris(return_X_y = True)  \n",
    "  \n",
    "# Splitting the dataset in training and test data  \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)  \n",
    "  \n",
    "# Training the model using the Support Vector Classification class of sklearn  \n",
    "svc = SVC()  \n",
    "svc.fit(X_train, Y_train)  \n",
    "  \n",
    "# Computing the accuracy_score of the model  \n",
    "Y_pred = svc.predict(X_test)  \n",
    "score = accuracy_score(Y_test, Y_pred)  \n",
    "print(score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "65d21df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 2, 1, 1, 2, 0, 2, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "768f2a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [Only, graded, assignment, Midterm, Final, Rea...\n",
       "1       [Final, grade, based, two, exam, reading, quiz...\n",
       "2       [Class, super, easy, One, reading, quiz, week,...\n",
       "3       [Lecture, could, dry, time, I, still, liked, c...\n",
       "4       [Alex, excellent, lecturer, Insightful, even, ...\n",
       "                              ...                        \n",
       "1095    [Shes, fair, I, got, away, calling, Karl, Marx...\n",
       "1096    [Professor, klochko, cool, accent, make, hard,...\n",
       "1097    [Definitely, greatest, thing, since, slice, br...\n",
       "1098    [Shes, personal, almost, harsh, point, The, cl...\n",
       "1099    [Klochko, unpopular, Sociology, professor, OSU...\n",
       "Name: text_lemmatized, Length: 1100, dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmp_df['text_lemmatized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "1609d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "### now that we are done, lets try and redo a step we tried earlier, namely the tokenizer and tfdf cmd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "class NewTfidfVectorizer(TfidfVectorizer):\n",
    "    def _word_ngrams(self, tokens, stop_words=None):\n",
    "\n",
    "        # First get tokens without stop words\n",
    "        tokens = super(TfidfVectorizer, self)._word_ngrams(tokens, None)\n",
    "        if stop_words is not None:\n",
    "            new_tokens=[]\n",
    "            for token in tokens:\n",
    "                split_words = token.split(' ')\n",
    "\n",
    "                # Only check the first and last word for stop words\n",
    "                if split_words[0] not in stop_words and split_words[-1] not in stop_words:\n",
    "                    new_tokens.append(token)\n",
    "            return new_tokens\n",
    "\n",
    "        return tokens\n",
    "    \n",
    "vectorizer = NewTfidfVectorizer(stop_words='english', ngram_range=(2,3))\n",
    "# vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0c3d2d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043    ['Loved', 'Jungers!', 'She', 'made', 'everythi...\n",
       "122     ['The', 'test', 'class', 'ridiculous', 'made',...\n",
       "470     ['If', 'psychology', 'major', 'NO', 'point', '...\n",
       "765     ['midterm', 'final', 'group', 'presentation', ...\n",
       "2       ['Class', 'super', 'easy', 'One', 'reading', '...\n",
       "                              ...                        \n",
       "62      ['Really', 'great', 'guy', 'great', 'class', '...\n",
       "868     ['Professor', 'Harris', 'nice', 'I', 'found', ...\n",
       "36      ['Genuinely', 'interested', 'teaching', 'A', '...\n",
       "342     ['I', 'dont', 'know', 'class', 'psych', 'woman...\n",
       "529     ['Dr', 'Cudeck', 'brilliant', 'psychologistThe...\n",
       "Name: text_lemmatized, Length: 737, dtype: object"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_lemmatized_all = X_train.astype(str)\n",
    "text_lemmatized_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "917cba59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<737x19455 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 22511 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now, try the above cmd on the code from earlier regarding the training set \n",
    "#tf_idf_matrix = pd.DataFrame(\n",
    "#    tfidf_vect.fit_transform(X_train).toarray(), \n",
    "#    columns=tfidf_vect.get_feature_names()\n",
    "#)\n",
    "Xtrain_mat2 =vectorizer.fit_transform(text_lemmatized_all)\n",
    "Xtrain_mat2 ### good, this is what we want; now we can try some things  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c3695754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab impossible</th>\n",
       "      <th>abbreviated recorded</th>\n",
       "      <th>abbreviated recorded lecture</th>\n",
       "      <th>abcd test</th>\n",
       "      <th>abcd test average</th>\n",
       "      <th>ability clarify</th>\n",
       "      <th>ability he best</th>\n",
       "      <th>ability mainly</th>\n",
       "      <th>able pas</th>\n",
       "      <th>able pas class</th>\n",
       "      <th>...</th>\n",
       "      <th>zero curve</th>\n",
       "      <th>zero curve point</th>\n",
       "      <th>zero quiz</th>\n",
       "      <th>zero quiz test</th>\n",
       "      <th>zone bring</th>\n",
       "      <th>zone bring snack</th>\n",
       "      <th>zoom class</th>\n",
       "      <th>zoom class super</th>\n",
       "      <th>zoom got</th>\n",
       "      <th>zoom got good</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>737 rows × 19455 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ab impossible  abbreviated recorded  abbreviated recorded lecture  \\\n",
       "0              0.0                   0.0                           0.0   \n",
       "1              0.0                   0.0                           0.0   \n",
       "2              0.0                   0.0                           0.0   \n",
       "3              0.0                   0.0                           0.0   \n",
       "4              0.0                   0.0                           0.0   \n",
       "..             ...                   ...                           ...   \n",
       "732            0.0                   0.0                           0.0   \n",
       "733            0.0                   0.0                           0.0   \n",
       "734            0.0                   0.0                           0.0   \n",
       "735            0.0                   0.0                           0.0   \n",
       "736            0.0                   0.0                           0.0   \n",
       "\n",
       "     abcd test  abcd test average  ability clarify  ability he best  \\\n",
       "0          0.0                0.0              0.0              0.0   \n",
       "1          0.0                0.0              0.0              0.0   \n",
       "2          0.0                0.0              0.0              0.0   \n",
       "3          0.0                0.0              0.0              0.0   \n",
       "4          0.0                0.0              0.0              0.0   \n",
       "..         ...                ...              ...              ...   \n",
       "732        0.0                0.0              0.0              0.0   \n",
       "733        0.0                0.0              0.0              0.0   \n",
       "734        0.0                0.0              0.0              0.0   \n",
       "735        0.0                0.0              0.0              0.0   \n",
       "736        0.0                0.0              0.0              0.0   \n",
       "\n",
       "     ability mainly  able pas  able pas class  ...  zero curve  \\\n",
       "0               0.0       0.0             0.0  ...         0.0   \n",
       "1               0.0       0.0             0.0  ...         0.0   \n",
       "2               0.0       0.0             0.0  ...         0.0   \n",
       "3               0.0       0.0             0.0  ...         0.0   \n",
       "4               0.0       0.0             0.0  ...         0.0   \n",
       "..              ...       ...             ...  ...         ...   \n",
       "732             0.0       0.0             0.0  ...         0.0   \n",
       "733             0.0       0.0             0.0  ...         0.0   \n",
       "734             0.0       0.0             0.0  ...         0.0   \n",
       "735             0.0       0.0             0.0  ...         0.0   \n",
       "736             0.0       0.0             0.0  ...         0.0   \n",
       "\n",
       "     zero curve point  zero quiz  zero quiz test  zone bring  \\\n",
       "0                 0.0        0.0             0.0         0.0   \n",
       "1                 0.0        0.0             0.0         0.0   \n",
       "2                 0.0        0.0             0.0         0.0   \n",
       "3                 0.0        0.0             0.0         0.0   \n",
       "4                 0.0        0.0             0.0         0.0   \n",
       "..                ...        ...             ...         ...   \n",
       "732               0.0        0.0             0.0         0.0   \n",
       "733               0.0        0.0             0.0         0.0   \n",
       "734               0.0        0.0             0.0         0.0   \n",
       "735               0.0        0.0             0.0         0.0   \n",
       "736               0.0        0.0             0.0         0.0   \n",
       "\n",
       "     zone bring snack  zoom class  zoom class super  zoom got  zoom got good  \n",
       "0                 0.0         0.0               0.0       0.0            0.0  \n",
       "1                 0.0         0.0               0.0       0.0            0.0  \n",
       "2                 0.0         0.0               0.0       0.0            0.0  \n",
       "3                 0.0         0.0               0.0       0.0            0.0  \n",
       "4                 0.0         0.0               0.0       0.0            0.0  \n",
       "..                ...         ...               ...       ...            ...  \n",
       "732               0.0         0.0               0.0       0.0            0.0  \n",
       "733               0.0         0.0               0.0       0.0            0.0  \n",
       "734               0.0         0.0               0.0       0.0            0.0  \n",
       "735               0.0         0.0               0.0       0.0            0.0  \n",
       "736               0.0         0.0               0.0       0.0            0.0  \n",
       "\n",
       "[737 rows x 19455 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_matrix_ngramplus = pd.DataFrame(\n",
    "    vectorizer.fit_transform(text_lemmatized_all).toarray(), \n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "tf_idf_matrix_ngramplus ## good, this demonstrates what I need. We can integrate this into the next version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868303e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
