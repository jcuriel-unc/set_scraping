{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417514ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### install openai \n",
    "#!{sys.executable} -m pip install openai\n",
    "#import openai\n",
    "\n",
    "## read in pkgs \n",
    "import sys\n",
    "import os\n",
    "# !{sys.executable} -m pip install xgboost==1.7.5 # note: needed since it looks like anaconda installs an earlier version \n",
    "# of the package, which is not helpful. 1.7.5 allows for the categorical data of interest to be used. \n",
    "\n",
    "# !{sys.executable} -m pip install requests #; this code here can be used to install packages on anaconda/jupyter notebook \n",
    "### I believe the below should be installed by default \n",
    "import requests # web scraping \n",
    "from bs4 import BeautifulSoup # for web scraping \n",
    "import itertools # for efficient operation of loops \n",
    "import pandas as pd # necessary for reading in, creating, and manipulating data frames \n",
    "import csv ## for importing/exporting csvs \n",
    "import glob ## for finding files in path\n",
    "import re\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6feb46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\"\n",
    "model = 'text-davinci-003'\n",
    "\n",
    "### now we will want to create the column in the new data frame, and also read in the data of interest from persp\n",
    "rmp_df_sub = pd.read_csv(\"sample_peRspective_coded342obs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf3794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>TOXICITY</th>\n",
       "      <th>SEVERE_TOXICITY</th>\n",
       "      <th>IDENTITY_ATTACK</th>\n",
       "      <th>INSULT</th>\n",
       "      <th>PROFANITY</th>\n",
       "      <th>SEXUALLY_EXPLICIT</th>\n",
       "      <th>THREAT</th>\n",
       "      <th>FLIRTATION</th>\n",
       "      <th>ATTACK_ON_AUTHOR</th>\n",
       "      <th>...</th>\n",
       "      <th>pb_pol_affil</th>\n",
       "      <th>complex</th>\n",
       "      <th>constructive</th>\n",
       "      <th>reflective</th>\n",
       "      <th>outrage_agg</th>\n",
       "      <th>personal_attack_agg</th>\n",
       "      <th>prejudice_agg</th>\n",
       "      <th>openai_is_misrep_prob</th>\n",
       "      <th>openai_somewhat_misrep_prob</th>\n",
       "      <th>openai_not_misrep_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>0.021808</td>\n",
       "      <td>0.013152</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.247846</td>\n",
       "      <td>0.264617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1009</td>\n",
       "      <td>0.112437</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.042080</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.007767</td>\n",
       "      <td>0.331722</td>\n",
       "      <td>0.625810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010</td>\n",
       "      <td>0.006440</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.209196</td>\n",
       "      <td>0.387362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1013</td>\n",
       "      <td>0.036399</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>0.019999</td>\n",
       "      <td>0.016275</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.350796</td>\n",
       "      <td>0.226716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1016</td>\n",
       "      <td>0.187442</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.094167</td>\n",
       "      <td>0.027001</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.375103</td>\n",
       "      <td>0.628583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>985</td>\n",
       "      <td>0.351861</td>\n",
       "      <td>0.010529</td>\n",
       "      <td>0.006327</td>\n",
       "      <td>0.227703</td>\n",
       "      <td>0.352205</td>\n",
       "      <td>0.227896</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>0.456535</td>\n",
       "      <td>0.564237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>988</td>\n",
       "      <td>0.338998</td>\n",
       "      <td>0.007668</td>\n",
       "      <td>0.011469</td>\n",
       "      <td>0.340328</td>\n",
       "      <td>0.099306</td>\n",
       "      <td>0.014096</td>\n",
       "      <td>0.008492</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>0.675417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>990</td>\n",
       "      <td>0.452437</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.008103</td>\n",
       "      <td>0.493893</td>\n",
       "      <td>0.109209</td>\n",
       "      <td>0.008670</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.289088</td>\n",
       "      <td>0.788002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>995</td>\n",
       "      <td>0.286744</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.269578</td>\n",
       "      <td>0.023995</td>\n",
       "      <td>0.008552</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.170271</td>\n",
       "      <td>0.872965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>998</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.011959</td>\n",
       "      <td>0.012961</td>\n",
       "      <td>0.006104</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.264802</td>\n",
       "      <td>0.791277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "      <td>-99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     text_id  TOXICITY  SEVERE_TOXICITY  IDENTITY_ATTACK    INSULT  PROFANITY  \\\n",
       "0       1001  0.052800         0.001554         0.004717  0.024511   0.021808   \n",
       "1       1009  0.112437         0.001841         0.004532  0.042080   0.027820   \n",
       "2       1010  0.006440         0.000668         0.002127  0.006401   0.011321   \n",
       "3       1013  0.036399         0.000877         0.002266  0.019999   0.016275   \n",
       "4       1016  0.187442         0.002069         0.002719  0.094167   0.027001   \n",
       "..       ...       ...              ...              ...       ...        ...   \n",
       "337      985  0.351861         0.010529         0.006327  0.227703   0.352205   \n",
       "338      988  0.338998         0.007668         0.011469  0.340328   0.099306   \n",
       "339      990  0.452437         0.009346         0.008103  0.493893   0.109209   \n",
       "340      995  0.286744         0.003338         0.006068  0.269578   0.023995   \n",
       "341      998  0.022257         0.000753         0.002627  0.011959   0.012961   \n",
       "\n",
       "     SEXUALLY_EXPLICIT    THREAT  FLIRTATION  ATTACK_ON_AUTHOR  ...  \\\n",
       "0             0.013152  0.007547    0.247846          0.264617  ...   \n",
       "1             0.014272  0.007767    0.331722          0.625810  ...   \n",
       "2             0.005898  0.006557    0.209196          0.387362  ...   \n",
       "3             0.006045  0.006298    0.350796          0.226716  ...   \n",
       "4             0.004807  0.006803    0.375103          0.628583  ...   \n",
       "..                 ...       ...         ...               ...  ...   \n",
       "337           0.227896  0.006693    0.456535          0.564237  ...   \n",
       "338           0.014096  0.008492    0.361905          0.675417  ...   \n",
       "339           0.008670  0.007288    0.289088          0.788002  ...   \n",
       "340           0.008552  0.006770    0.170271          0.872965  ...   \n",
       "341           0.006104  0.006434    0.264802          0.791277  ...   \n",
       "\n",
       "     pb_pol_affil  complex  constructive  reflective  outrage_agg  \\\n",
       "0             0.0        0             0           0            0   \n",
       "1             0.0        0             0           0            1   \n",
       "2             0.0        0             0           0            0   \n",
       "3             0.0        0             0           0            0   \n",
       "4             0.0        0             0           0            1   \n",
       "..            ...      ...           ...         ...          ...   \n",
       "337           0.0        0             0           0            0   \n",
       "338           0.0        0             0           0            0   \n",
       "339           0.0        0             0           0            3   \n",
       "340           0.0        0             0           0            2   \n",
       "341           0.0        0             0           0            0   \n",
       "\n",
       "     personal_attack_agg  prejudice_agg openai_is_misrep_prob  \\\n",
       "0                      0            0.0                   -99   \n",
       "1                      0            0.0                   -99   \n",
       "2                      0            0.0                   -99   \n",
       "3                      0            0.0                   -99   \n",
       "4                      1            0.0                   -99   \n",
       "..                   ...            ...                   ...   \n",
       "337                    0            0.0                   -99   \n",
       "338                    0            0.0                   -99   \n",
       "339                    0            0.0                   -99   \n",
       "340                    2            0.0                   -99   \n",
       "341                    0            0.0                   -99   \n",
       "\n",
       "    openai_somewhat_misrep_prob openai_not_misrep_prob  \n",
       "0                           -99                    -99  \n",
       "1                           -99                    -99  \n",
       "2                           -99                    -99  \n",
       "3                           -99                    -99  \n",
       "4                           -99                    -99  \n",
       "..                          ...                    ...  \n",
       "337                         -99                    -99  \n",
       "338                         -99                    -99  \n",
       "339                         -99                    -99  \n",
       "340                         -99                    -99  \n",
       "341                         -99                    -99  \n",
       "\n",
       "[342 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### now create three new columns for the df \n",
    "rmp_df_sub['openai_is_misrep_prob'] = -99\n",
    "rmp_df_sub['openai_somewhat_misrep_prob'] = -99\n",
    "rmp_df_sub['openai_not_misrep_prob'] = -99\n",
    "rmp_df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78728963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n"
     ]
    }
   ],
   "source": [
    "### attempt at loop \n",
    "comment_list = rmp_df_sub['comment']\n",
    "for i, element in enumerate(comment_list):\n",
    "    misrep_prompt = f'''\n",
    "    Calculate the probability that a comment belongs to each of the following ordinal categories: \"misrepresentation\" or\n",
    "    \"somewhat misrepresentation\" or \"not misrepresentation\". A comment that is misreprsentation is a statement that engages \n",
    "    in the logical fallacies of straw man or misrepresentation of empirical data/actions. \n",
    "    Such statements assign malintent by a person and uses hyperbole to the point of absurdity.\n",
    "\n",
    "    An example of a statement that is misrepresentation: The professor wants their students to fail and suffer. \n",
    "    She literally could not teach if her life depended on it. \n",
    "\n",
    "\n",
    "    A statement that is somewhat misrepresentation: she also assigns busy work that is completely pointless. \n",
    "    And she is annoying-exaggerates her lame east coast accent. \n",
    "\n",
    "    A statement that is not misrepresentation: His lectures were boring, but he gave us handouts to follow along with, \n",
    "    so that was helpful\n",
    "\n",
    "\n",
    "    What is the probability a comment belongs to each one of these categories?\n",
    "    \"\"\"\n",
    "    {comment_list[i]}\n",
    "    \"\"\"\n",
    "    '''\n",
    "    print(i)\n",
    "    ### try here; pass otherwise and gen individually \n",
    "    try:\n",
    "        response = openai.Completion.create(model='text-davinci-003',\n",
    "                                        prompt=misrep_prompt,\n",
    "                                        max_tokens=200, # content getting cut off; not ideal, but ah well \n",
    "                                        logprobs=1)\n",
    "    ## now grab the probs \n",
    "        token_logprobs = response['choices'][0]['logprobs']['tokens']\n",
    "### let's try combining all elements \n",
    "        l = ' '.join(token_logprobs)\n",
    "#l \n",
    "## now let's split and extract only numbers \n",
    "        temp = re.findall(r'\\d+', l)\n",
    "        res = list(map(int, temp))\n",
    "    ### now that we have a list of the three probs, let's store.\n",
    "    ## note. The first val is misrep, second somewhat misrep, and third not misrep \n",
    "        rmp_df_sub.at[i,'openai_is_misrep_prob'] = res[0]\n",
    "        rmp_df_sub.at[i,'openai_somewhat_misrep_prob'] = res[1]\n",
    "        rmp_df_sub.at[i,'openai_not_misrep_prob'] = res[2]\n",
    "        ## seems to be that if something cannot be calculated (i.e. not enough info) then it has an error; can usually \n",
    "        # code as not misrep \n",
    "    except: # report the observation num (with 0 being 1) that failed to store/run \n",
    "        pass\n",
    "        print(\"Error occurred for observation \", rmp_df_sub['text_id'][i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b4b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### everything ran! Let's write out a csv to analyze in r \n",
    "rmp_df_sub.to_csv(\"ml_applied2sample_peRspective_coded342obs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8799f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_30656\\3243971013.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  most_misrep_df['openai_is_misrep_prob'] = -99\n",
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_30656\\3243971013.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  most_misrep_df['openai_somewhat_misrep_prob'] = -99\n",
      "C:\\Users\\j-curiel\\AppData\\Local\\Temp\\ipykernel_30656\\3243971013.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  most_misrep_df['openai_not_misrep_prob'] = -99\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35     The tests in this class were ridiculous, they ...\n",
       "40     This man has no buisiness being a college prof...\n",
       "56     She's clear as mud when it comes to everything...\n",
       "60     Terrible terrible terrible terrible professor!...\n",
       "82     Heavy weighted classes. Would not recommend an...\n",
       "95     Lectures are actually really interesting and w...\n",
       "112    Try to avoid this professor at all costs. Lect...\n",
       "119    If you can avoid professor , DO IT. A ridiculo...\n",
       "125    Takes TopHat attendance (ends up being 15% of ...\n",
       "147    She cares that her students learn, but she doe...\n",
       "174    This class is useless for research and Dr.  is...\n",
       "198    This class is unnecessarily tedious and diffic...\n",
       "245     sucks. get another professor if you can. his ...\n",
       "262    Don't know how its possible but he never actua...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### we want to diagnose here with diff prompt and subset of code.\n",
    "most_misrep_df = rmp_df_sub.loc[rmp_df_sub['out_misrep'] == 2]\n",
    "most_misrep_df['openai_is_misrep_prob'] = -99\n",
    "most_misrep_df['openai_somewhat_misrep_prob'] = -99\n",
    "most_misrep_df['openai_not_misrep_prob'] = -99\n",
    "comment_list2 = most_misrep_df['comment']\n",
    "comment_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30a6401d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3399559350.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[12], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    misrep_prompt2 = f'''\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "### with these 14 obs, we can now try a different prompt and such ; maybe reverse prompt? \n",
    "    misrep_prompt2 = f'''\n",
    "    Calculate the probability that a comment belongs to each of the following ordinal categories: \"misrepresentation\" or\n",
    "    \"somewhat misrepresentation\" or \"not misrepresentation\". A comment that is misreprsentation is a statement that engages \n",
    "    in the logical fallacies of straw man or misrepresentation of empirical data/actions. \n",
    "    Such statements assign malintent by a person and uses hyperbole to the point of absurdity.\n",
    "\n",
    "    An example of a statement that is misrepresentation: The professor wants their students to fail and suffer. \n",
    "    She literally could not teach if her life depended on it. \n",
    "\n",
    "\n",
    "    A statement that is somewhat misrepresentation: she also assigns busy work that is completely pointless. \n",
    "    And she is annoying-exaggerates her lame east coast accent. \n",
    "\n",
    "    A statement that is not misrepresentation: His lectures were boring, but he gave us handouts to follow along with, \n",
    "    so that was helpful\n",
    "\n",
    "\n",
    "    What is the probability a comment belongs to each one of these categories?\n",
    "    \"\"\"\n",
    "    {comment_list2[2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b497790a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985da2c2df3d4860ba339fb1b21fa79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\j-curiel\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57d8a2890004500b39d612ec75a158e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309a12aac22d4e3087265eb95a358181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ccfa4bdcdb43c3a9589613e7f4c4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "### try code from ml response \n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "#  BertTokenizer to tokenize the comments and prepare them for input to the BERT model\n",
    "\n",
    "# Load the pre-trained BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "#BertForSequenceClassification model to obtain the logits,\n",
    "# which are subsequently converted to probabilities using the softmax function.\n",
    "\n",
    "# Set the device (CPU or GPU) for inference\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7374d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of comments\n",
    "comments = [\n",
    "    \"This is a great product!\",\n",
    "    \"You're an idiot!\",\n",
    "    \"I love your work!\",\n",
    "    \"Your service is terrible.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fc3375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: This is a great product!\n",
      "Toxicity Probability: 0.6461\n",
      "\n",
      "Comment: You're an idiot!\n",
      "Toxicity Probability: 0.6485\n",
      "\n",
      "Comment: I love your work!\n",
      "Toxicity Probability: 0.6083\n",
      "\n",
      "Comment: Your service is terrible.\n",
      "Toxicity Probability: 0.7152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the comments\n",
    "encoded_inputs = tokenizer(comments, padding=True, truncation=True, return_tensors='pt')\n",
    "input_ids = encoded_inputs['input_ids'].to(device)\n",
    "attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    logits = model(input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "# Apply softmax to obtain probabilities\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "toxic_probs = probs[:, 1]  # Probability of being toxic (class index 1)\n",
    "\n",
    "# Print the probabilities\n",
    "for comment, prob in zip(comments, toxic_probs):\n",
    "    print(f\"Comment: {comment}\")\n",
    "    print(f\"Toxicity Probability: {prob.item():.4f}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c28e7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2023,  2003,  1037,  2307,  4031,   999,   102],\n",
       "        [  101,  2017,  1005,  2128,  2019, 10041,   999,   102],\n",
       "        [  101,  1045,  2293,  2115,  2147,   999,   102,     0],\n",
       "        [  101,  2115,  2326,  2003,  6659,  1012,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "330d9498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The professor wants their students to fail and suffer. She literally could not teach if her life depended on it.'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### given what we have, lets try and code a new misrep dictionary \n",
    "defn_cv = pd.read_csv(\"toxicity_defns.csv\", encoding='cp1252')\n",
    "defn_cv[\"Example\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d172c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f5afacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### try more code, this time using the generic toxic field \n",
    "import openai\n",
    "\n",
    "\n",
    "def calculate_toxicity_probabilities(comments):\n",
    "    prompt = \"This is a comment toxicity classification task. Classify the following comments as toxic or non-toxic:\\n\\n\" + \"\\n\".join(comments)\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=2,\n",
    "        temperature=0,\n",
    "        n=2,\n",
    "        stop=None,\n",
    "        logprobs=1\n",
    "    )\n",
    "    \n",
    "    choices = response.choices[0]\n",
    "    log_probs = choices['logprobs']['top_logprobs'][0]\n",
    "    toxic_probability = 10 ** log_probs['\\n']\n",
    "    \n",
    "    return toxic_probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "659e23ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity Probability: 0.9948\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "comments = [\n",
    "    \"This is a great product!\",\n",
    "    \"You're an idiot!\",\n",
    "    \"I love your work!\",\n",
    "    \"Your service is terrible.\"\n",
    "]\n",
    "\n",
    "toxic_prob = calculate_toxicity_probabilities(comments[2])\n",
    "print(f\"Toxicity Probability: {toxic_prob:.4f}\") ## so this is a garbage model ; 0.9952 prob of toxicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7482fe06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a great product!'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3857124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"This is a comment toxicity classification task. Classify the following comments as toxic or non-toxic:\\n\\n\" + \"\\n\".join(comments[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e7c37885",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=2,\n",
    "        temperature=0,\n",
    "        n=2,\n",
    "        stop=None,\n",
    "        logprobs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb571c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x25d6b69e810> JSON: {\n",
       "  \"\\n\": -0.0011394074\n",
       "}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = response.choices[0]\n",
    "choices\n",
    "log_probs = choices['logprobs']['top_logprobs'][0]\n",
    "log_probs ### gets me a new line with a numeric value \n",
    "\n",
    "#toxic_probability = 10 ** log_probs['\\n'] ## this 'negative' is not working, since it corresponds to nothing. However\n",
    "# it is trying to get the numeric value here. If we can do that, then we are in luck. \n",
    "#toxic_probability ## excellent, this works! Now, we should be able to get at the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24cbbe92",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## num extraction \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m temp1 \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43md+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m res1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, temp1))\n\u001b[0;32m      4\u001b[0m res1\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\re.py:241\u001b[0m, in \u001b[0;36mfindall\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindall\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    239\u001b[0m \n\u001b[0;32m    240\u001b[0m \u001b[38;5;124;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "## num extraction \n",
    "temp1 = re.findall(r'\\d+', log_probs)\n",
    "res1 = list(map(int, temp1))\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb3475a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x25d6b69f950> JSON: {\n",
       "  \"\\n\": -0.0011527737\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3adf81f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0011527737"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs['\\n'] ## this works ! Will it work continuosly, though? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "520a4ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Misrepresentation</td>\n",
       "      <td>A statement that engages in the logical fallac...</td>\n",
       "      <td>The professor wants their students to fail and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional language</td>\n",
       "      <td>Statements that employ the appeal to emotion l...</td>\n",
       "      <td>Terrible terrible terrible terrible professor!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ideologically extremizing language</td>\n",
       "      <td>Such statements Identify a divisive issue as p...</td>\n",
       "      <td>Do not even bother unless you are a democrat. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Slippery slope</td>\n",
       "      <td>Statements that employ the false dichotomy, sl...</td>\n",
       "      <td>Having this professor continue to teach will r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Insulting/belittling</td>\n",
       "      <td>Language that engages in disrespectful, denigr...</td>\n",
       "      <td>AVOID AT ALL COSTS. This guy is HORRIBLE. No i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mockery/sarcasm</td>\n",
       "      <td>Statements where the person is treated as the ...</td>\n",
       "      <td>She's clear as mud when it comes to everything...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Threatening</td>\n",
       "      <td>Threatens or demand specific, and often violen...</td>\n",
       "      <td>This professor should be shot.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Dimension  \\\n",
       "0                   Misrepresentation   \n",
       "1                  Emotional language   \n",
       "2  Ideologically extremizing language   \n",
       "3                      Slippery slope   \n",
       "4                Insulting/belittling   \n",
       "5                     Mockery/sarcasm   \n",
       "6                         Threatening   \n",
       "\n",
       "                                          Definition  \\\n",
       "0  A statement that engages in the logical fallac...   \n",
       "1  Statements that employ the appeal to emotion l...   \n",
       "2  Such statements Identify a divisive issue as p...   \n",
       "3  Statements that employ the false dichotomy, sl...   \n",
       "4  Language that engages in disrespectful, denigr...   \n",
       "5  Statements where the person is treated as the ...   \n",
       "6  Threatens or demand specific, and often violen...   \n",
       "\n",
       "                                             Example  \n",
       "0  The professor wants their students to fail and...  \n",
       "1  Terrible terrible terrible terrible professor!...  \n",
       "2  Do not even bother unless you are a democrat. ...  \n",
       "3  Having this professor continue to teach will r...  \n",
       "4  AVOID AT ALL COSTS. This guy is HORRIBLE. No i...  \n",
       "5  She's clear as mud when it comes to everything...  \n",
       "6                    This professor should be shot.   "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_probs['\\n'])\n",
    "defn_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10f05a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A comment like ''The professor wants their students to fail and suffer. She literally could not teach if her life depended on it.'' would be considered misrepresentation\""
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### create dfn objects and such \n",
    "defn_misrep = defn_cv['Definition'][0]\n",
    "misrep_ex =  defn_cv['Example'][0]\n",
    "misrep_ex = \"A comment like ''\" + misrep_ex + \"''\" \" would be considered misrepresentation\"\n",
    "misrep_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "96155b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### improved code here, where a definition and such can be provided. \n",
    "import openai\n",
    "\n",
    "#openai.api_key = 'YOUR_OPENAI_API_KEY'\n",
    "\n",
    "def calculate_misrep_probability(comment, definition, example):\n",
    "    prompt = f\"Classify the following comment as misrepresentation or not misrepresentation:\\n\\n\\\"{comment}\\\"\\n\\nToxicity Definition: {definition}\\n\\nExample: {example}\\n\\nLabel:\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=1,\n",
    "        temperature=0,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        logprobs=1\n",
    "    )\n",
    "    \n",
    "    choices = response.choices[0]\n",
    "    log_probs = choices['logprobs']['top_logprobs'][0]\n",
    "    toxic_probability = 10 ** log_probs['\\n']\n",
    "    \n",
    "    return toxic_probability\n",
    "\n",
    "# Example usage\n",
    "#comment = \"You're an idiot!\"\n",
    "#definition = \"Comments that contain personal attacks or offensive language.\"\n",
    "#example = \"A comment like 'You are a worthless moron!' would be considered toxic.\"\n",
    "\n",
    "#toxic_prob = calculate_toxicity_probability(comment, definition, example)\n",
    "#print(f\"Toxicity Probability: {toxic_prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "1da5d6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       is awesome. Lecture isn't necessary and she e...\n",
       "1      I'm in his class at the moment. I have tried s...\n",
       "2      Excellent teacher. Enjoys and knows his subjec...\n",
       "3      His lectures were boring, but he gave us hando...\n",
       "4                      Didn't teach us anything. Boring.\n",
       "                             ...                        \n",
       "337    Dr.  cares a lot about environmental health an...\n",
       "338    Horrible, very unorganized, tough grader, he's...\n",
       "339    Just Ridiculous, he makes his quizzes and test...\n",
       "340    Wouldn't recommend taking this class with him....\n",
       "341    This is his first semester teaching here. He i...\n",
       "Name: comment, Length: 342, dtype: object"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5c95b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Classify the following comment as misrepresentation or non-misrepresentation:\\n\\n\\\"{comment_list[0]}\\\"\\n\\nToxicity Definition: {defn_misrep}\\n\\nExample: {misrep_ex}\\n\\nLabel:\"\n",
    "    \n",
    "response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=1,\n",
    "        temperature=0,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        logprobs=1\n",
    "    )\n",
    "    \n",
    "choices = response.choices[0]\n",
    "# choices # so what's going on is that the \\n was simply coded up above, and now it is either misrepresent or not \n",
    "#log_probs = choices['logprobs']['top_logprobs'][1]\n",
    "#toxic_probability = 10 ** log_probs['misrepresent']\n",
    "#toxic_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c720f028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x25d3006e950> JSON: {\n",
       "  \" Mis\": -0.0041302717\n",
       "}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices\n",
    "choices\n",
    "log_probs = choices['logprobs']['top_logprobs'][0]\n",
    "log_probs\n",
    "#toxic_probability = 10 ** log_probs['misrepresent']\n",
    "#toxic_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "57a33376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905347778550594"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = choices['logprobs']['top_logprobs'][0]\n",
    "toxic_probability = 10 ** log_probs[\" Mis\"]\n",
    "toxic_probability ### ok, this worked. Let's check the other prob \n",
    "\n",
    "### yep, this is way too high to actually work. This needs to be far lower, yet it is very high. We will need some improved \n",
    "# data or an applied ML model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "db70c0d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m log_probs1 \u001b[38;5;241m=\u001b[39m \u001b[43mchoices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#log_probs1\u001b[39;00m\n\u001b[0;32m      3\u001b[0m non_tox_prob \u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m log_probs1[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepresent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "log_probs1 = choices['logprobs']['top_logprobs'][1]\n",
    "#log_probs1\n",
    "non_tox_prob =  10 ** log_probs1[\"represent\"]\n",
    "non_tox_prob # so this is still very high... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5f851c66",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[133], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m toxic_prob \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_misrep_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomment_list2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m35\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefn_misrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmisrep_ex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToxicity Probability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtoxic_prob\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[108], line 21\u001b[0m, in \u001b[0;36mcalculate_misrep_probability\u001b[1;34m(comment, definition, example)\u001b[0m\n\u001b[0;32m     19\u001b[0m choices \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     20\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m choices[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_logprobs\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 21\u001b[0m toxic_probability \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[43mlog_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m toxic_probability\n",
      "\u001b[1;31mKeyError\u001b[0m: '\\n'"
     ]
    }
   ],
   "source": [
    "toxic_prob = calculate_misrep_probability(comment_list2[35], defn_misrep, misrep_ex)\n",
    "print(f\"Toxicity Probability: {toxic_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46bf181a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### looks like we can also create a model where the labeled data is used. The following are blocs of code for that purpose \n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config\n",
    "### these were loaded in successfully "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0825e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your labeled dataset class\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, tokenizer, comments, labels):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.comments = comments\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = self.comments[index]\n",
    "        label = self.labels[index]\n",
    "        inputs = self.tokenizer.encode_plus(comment, add_special_tokens=True, padding='max_length', max_length=128, truncation=True)\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "590d7791",
   "metadata": {},
   "outputs": [],
   "source": [
    "### have labled data \n",
    "# Prepare your labeled data\n",
    "comments = [\n",
    "    \"This is a great product!\",\n",
    "    \"You're an idiot!\",\n",
    "    \"I love your work!\",\n",
    "    \"Your service is terrible.\"\n",
    "]\n",
    "labels = [0, 1, 0, 1]  # 0: non-toxic, 1: toxic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af76ee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3591f1df78ba45fcb5bf104caf6f03e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\j-curiel\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\j-curiel\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ecd7e888294d90a524494d179950d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb970b0cb8874e3aabab3c28f11c3ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer and model configuration\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "#config = GPT2Config.from_pretrained('gpt2', num_labels=2)  # 2 classes: toxic and non-toxic; can expand as needed \n",
    "config = GPT2Config.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2784b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the labeled dataset\n",
    "tokenizer.add_special_tokens({'pad_token': '0'})\n",
    "dataset = LabeledDataset(tokenizer, comments, labels) # tokenizer above (from gpt2), with commens the field with comment data, \n",
    "# and the labels the 0s and 1s \n",
    "\n",
    "# Data loader\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "### check size of data loader \n",
    "# len(dataloader) # so it is a length of 2, so I think that is good \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c68640f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce7753dbc80445f81fb0987a9dd680c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6251c29072014ee394fc27bbc83e2d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x202b266a7c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Fine-tuning parameters\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4717660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  40, 1842,  534,  670,    0,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15],\n",
       "        [7120, 2139,  318, 7818,   13,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,   15,\n",
       "           15,   15,   15,   15,   15,   15,   15,   15]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### inspect the dataloader object\n",
    "#dataloader['input_ids']\n",
    "input_ids = batch['input_ids'].to(device)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e5059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Average Loss: 8.8977\n"
     ]
    }
   ],
   "source": [
    "# Fine-tuning loop; update on 6/28 makes it seem to work \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "save_path = 'path/to/save/model'\n",
    "\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3fde8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## screw it, lets see if we can use content moderation \n",
    "moderation_resp = openai.Moderation.create(input=comment_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7135c1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject id=modr-7VnfylIjKN78lEfbQBDLnV2AhUbhs at 0x25d3006ef90> JSON: {\n",
       "  \"id\": \"modr-7VnfylIjKN78lEfbQBDLnV2AhUbhs\",\n",
       "  \"model\": \"text-moderation-004\",\n",
       "  \"results\": [\n",
       "    {\n",
       "      \"categories\": {\n",
       "        \"hate\": false,\n",
       "        \"hate/threatening\": false,\n",
       "        \"self-harm\": false,\n",
       "        \"sexual\": false,\n",
       "        \"sexual/minors\": false,\n",
       "        \"violence\": false,\n",
       "        \"violence/graphic\": false\n",
       "      },\n",
       "      \"category_scores\": {\n",
       "        \"hate\": 5.877722e-07,\n",
       "        \"hate/threatening\": 1.8176392e-10,\n",
       "        \"self-harm\": 5.272974e-10,\n",
       "        \"sexual\": 4.2102602e-08,\n",
       "        \"sexual/minors\": 6.5878175e-10,\n",
       "        \"violence\": 1.7265573e-05,\n",
       "        \"violence/graphic\": 7.942838e-09\n",
       "      },\n",
       "      \"flagged\": false\n",
       "    }\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moderation_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a73064b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "My name is Adam.  I am trying to learn more about computer\n"
     ]
    }
   ],
   "source": [
    "completion = openai.Completion.create(model=\"text-davinci-003\", prompt=\"Hello world\")\n",
    "print(completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a5aaa53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"I love ice cream!\"\n",
    "response = openai.Completion.create(\n",
    "  engine=\"davinci\",\n",
    "  prompt=f\"Sentiment analysis: {text}\",\n",
    "  max_tokens=1,\n",
    "    logprobs=1\n",
    ")\n",
    "\n",
    "sentiment = response.choices[0].text.strip()\n",
    "print(sentiment) ### no!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a77ef79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<OpenAIObject at 0x25d2fea4540> JSON: {\n",
       "   \"finish_reason\": \"length\",\n",
       "   \"index\": 0,\n",
       "   \"logprobs\": {\n",
       "     \"text_offset\": [\n",
       "       37\n",
       "     ],\n",
       "     \"token_logprobs\": [\n",
       "       -0.7607072\n",
       "     ],\n",
       "     \"tokens\": [\n",
       "       \"\\n\"\n",
       "     ],\n",
       "     \"top_logprobs\": [\n",
       "       {\n",
       "         \"\\n\": -0.7607072\n",
       "       }\n",
       "     ]\n",
       "   },\n",
       "   \"text\": \"\\n\"\n",
       " }]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4568a7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4673358102325996"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-0.7607072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab25fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
