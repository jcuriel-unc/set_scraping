"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic"))
ggplot_persp_temp
summary(rmp_df_persp_sub$temp_var)
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4)
ggplot_persp_temp
str(rmp_df_persp_sub$temp_var)
str(rmp_df_persp_sub)
ggplot_persp_temp
rmp_df_persp_sub$temp_var <- rmp_df_persp_sub[models2run[i]]
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1))
ggplot_persp_temp
rmp_df_persp_sub$temp_var <- unlist(rmp_df_persp_sub$temp_var)
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1))
ggplot_persp_temp
rmp_df_persp_sub$temp_var <- rmp_df_persp_sub[models2run[i]]
rmp_df_persp_sub$temp_var <- unlist(rmp_df_persp_sub$temp_var)
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1))
ggplot_persp_temp
## report medians
toxic_median <- rmp_df_persp_sub %>%
group_by(coded_toxic) %>%
quantile(temp_var, 0.5)
toxic_median
rmp_df_persp_sub$temp_var <- rmp_df_persp_sub[models2run[i]]
rmp_df_persp_sub$temp_var <- unlist(rmp_df_persp_sub$temp_var)
summary(rmp_df_persp_sub$temp_var)
## report medians
toxic_median <- rmp_df_persp_sub %>%
group_by(coded_toxic) %>%
summarize(quantile(temp_var, 0.5))
toxic_median
toxic_median[1]
toxic_median[2]
toxic_median[1,2]
toxic_med1 = toxic_median[2,2]
toxic_med1
library(grid)
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
grobTree(textGrob("Median values", x=0.8,  y=0.95, hjust=0))
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
grobTree(textGrob("Median values", x=0.8,  y=0.95, hjust=0,
gp=gpar(col="red", fontsize=13, fontface="italic")))
### create labels
header_label <- grobTree(textGrob("Median values", x=0.8,  y=0.95, hjust=0,
gp=gpar(col="red", fontsize=13, fontface="italic")))
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label)
ggplot_persp_temp
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="red", fontsize=13, fontface="italic")))
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label)
ggplot_persp_temp
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="red", fontsize=10, fontface="italic")))
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label)
ggplot_persp_temp
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="black", fontsize=10, fontface="italic")))
notox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med0), x=0.7,  y=0.85, hjust=0,
gp=gpar(col="#F8766D", fontsize=8, fontface="italic")))
### get median and place in text
toxic_med0 = toxic_median[1,2]
toxic_med1 = toxic_median[2,2]
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="black", fontsize=10, fontface="italic")))
notox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med0), x=0.7,  y=0.85, hjust=0,
gp=gpar(col="#F8766D", fontsize=8, fontface="italic")))
tox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med1), x=0.7,  y=0.75, hjust=0,
gp=gpar(col="#00BFC4", fontsize=8, fontface="italic")))
### now plot
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label) + annotation_custom(notox_label) +
annotation_custom(tox_label)
ggplot_persp_temp
toxic_med0
as.numeric(#F8766D)
as.numeric(toxic_med0)
### get median and place in text
toxic_med0 = round(as.numeric(toxic_median[1,2]),2)
toxic_med1 =  round(as.numeric(toxic_median[2,2]),2)
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="black", fontsize=10, fontface="italic")))
notox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med0), x=0.7,  y=0.85, hjust=0,
gp=gpar(col="#F8766D", fontsize=8, fontface="italic")))
tox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med1), x=0.7,  y=0.75, hjust=0,
gp=gpar(col="#00BFC4", fontsize=8, fontface="italic")))
### now plot
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label) + annotation_custom(notox_label) +
annotation_custom(tox_label)
ggplot_persp_temp
## now save
sv_name = paste0("plots/comparison",sep="/",models2run[i],sep=".png")
sv_name
## now save
sv_name = paste0("plots/comparison",sep="_",models2run[i],sep=".png")
sv_name
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="black", fontsize=10, fontface="italic")))
notox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med0), x=0.7,  y=0.85, hjust=0,
gp=gpar(col="#F8766D", fontsize=8)))
tox_label <- grobTree(textGrob(paste0("Non-toxic: ",toxic_med1), x=0.7,  y=0.75, hjust=0,
gp=gpar(col="#00BFC4", fontsize=8)))
### now plot
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label) + annotation_custom(notox_label) +
annotation_custom(tox_label)
## plot out
ggplot_persp_temp
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="black", fontsize=10, fontface="italic")))
notox_label <- grobTree(textGrob(paste0("Manual non-toxic: ",toxic_med0), x=0.7,  y=0.85, hjust=0,
gp=gpar(col="#F8766D", fontsize=8)))
tox_label <- grobTree(textGrob(paste0("Manual toxic: ",toxic_med1), x=0.7,  y=0.75, hjust=0,
gp=gpar(col="#00BFC4", fontsize=8)))
### now plot
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label) + annotation_custom(notox_label) +
annotation_custom(tox_label)
## plot out
ggplot_persp_temp
for (i in 1:length(models2run)) {
rmp_df_persp_sub$temp_var <- rmp_df_persp_sub[models2run[i]]
rmp_df_persp_sub$temp_var <- unlist(rmp_df_persp_sub$temp_var)
## report medians
toxic_median <- rmp_df_persp_sub %>%
group_by(coded_toxic) %>%
summarize(quantile(temp_var, 0.5))
### get median and place in text
toxic_med0 = round(as.numeric(toxic_median[1,2]),2)
toxic_med1 =  round(as.numeric(toxic_median[2,2]),2)
### create labels
header_label <- grobTree(textGrob("Median values", x=0.7,  y=0.95, hjust=0,
gp=gpar(col="black", fontsize=10, fontface="italic")))
notox_label <- grobTree(textGrob(paste0("Manual non-toxic: ",toxic_med0), x=0.7,  y=0.85, hjust=0,
gp=gpar(col="#F8766D", fontsize=8)))
tox_label <- grobTree(textGrob(paste0("Manual toxic: ",toxic_med1), x=0.7,  y=0.75, hjust=0,
gp=gpar(col="#00BFC4", fontsize=8)))
### now plot
ggplot_persp_temp <- ggplot(rmp_df_persp_sub, aes(x=temp_var,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title=paste0("Comparison of normalized aggregation of peRspective \n ", models2run[i], sep=" ",
"dimension") ,
x=paste0("Probability on peRspective ", models2run[i], sep=" ", "dimension"), y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic")) +
scale_x_continuous(limits = c(0, 1)) +
annotation_custom(header_label) + annotation_custom(notox_label) +
annotation_custom(tox_label)
## plot out
ggplot_persp_temp
## now save
sv_name = paste0("plots/comparison",sep="_",models2run[i],sep=".png")
ggsave(sv_name ,ggplot_persp_temp,
scale=1,width=9,height=6,units = c("in"), dpi=400,bg="white")
}
### load in packages
library(tidyverse) ## for efficient cleaning of data frames
library(wru) ## for predicting race of profs
library(foreign) ## for reading in of csv files and such
library(rstudioapi) ## for efficient grabbing of working directory info
library(ggplot2) ## for cool plots
library(irr)
library(arm)
library(peRspective)
library(grid)
###setting directory
main_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(main_wd)
persp_all_output <- readRDS("peRspective_data_test_run06242023.rds")
rmp_df <- read.csv("text_cleaning_data/scored_rmp_data06212023.csv")
rmp_df_persp_sub <- merge(persp_all_output, rmp_df,by.x="text_id", by.y="row_id")
names(rmp_df)
###create ID based on row number
rmp_df$row_id <- rownames(rmp_df)
rmp_df_persp_sub <- merge(persp_all_output, rmp_df,by.x="text_id", by.y="row_id")
nrow(rmp_df_persp_sub) ## looks like a success
library(tidyverse) ## for efficient cleaning of data frames
library(wru) ## for predicting race of profs
library(foreign) ## for reading in of csv files and such
library(rstudioapi) ## for efficient grabbing of working directory info
library(ggplot2) ## for cool plots
library(irr)
library(arm)
library(peRspective)
library(grid)
###setting directory
main_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(main_wd)
list.files()
## load in data
chatgpt_df <- read.csv("ml_applied2sample_peRspective_coded342obs.csv")
names(chatgpt_df)
###let's find the correlation between these
misrep_sub <- subset(chatgpt_df,select=c(text_id,out_misrep,openai_is_misrep_prob,openai_somewhat_misrep_prob,
openai_not_misrep_prob,comment))
?gather
### now change to long
misrep_sub_long <- misrep_sub %>% gather(key=type,value=probability, -c(text_id,out_misrep,comment) )
View(misrep_sub_long)
### that worked. Now let's find the IQR.
misrep_sub_long_iqr <- misrep_sub_long %>%
group_by(out_misrep) %>%
summarize(med_prob = median(probability), pct25 = quantile(probability,0.25),
pct75=quantile(probability,0.75))
View(misrep_sub_long_iqr)
## now categorize
misrep_sub_long$category <- "Not misrepresentation"
## now categorize
misrep_sub_long$category <- "Not misrepresentation"
## now categorize
misrep_sub_long$group <- "Not misrepresentation"
names(misrep_sub_long)
misrep_sub_long$group[type=="openai_somewhat_misrep_prob"] <- "Somewhat Misrepresentation"
class(misrep_sub_long)
### now change to long
misrep_sub_long <- misrep_sub %>% gather(key=type,value=probability, -c(text_id,out_misrep,comment) )
###let's find the correlation between these
misrep_sub <- subset(chatgpt_df,select=c(text_id,out_misrep,openai_is_misrep_prob,openai_somewhat_misrep_prob,
openai_not_misrep_prob,comment))
### now change to long
misrep_sub_long <- misrep_sub %>% gather(key=type,value=probability, -c(text_id,out_misrep,comment) )
###setting directory
main_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(main_wd)
## load in data
chatgpt_df <- read.csv("ml_applied2sample_peRspective_coded342obs.csv")
names(chatgpt_df)
###let's find the correlation between these
misrep_sub <- subset(chatgpt_df,select=c(text_id,out_misrep,openai_is_misrep_prob,openai_somewhat_misrep_prob,
openai_not_misrep_prob,comment))
### now change to long
misrep_sub_long <- misrep_sub %>%
gather(key=type,value=probability, -c(text_id,out_misrep,comment) )
### now change to long
misrep_sub_long = misrep_sub %>%
gather(key=type,value=probability, -c(text_id,out_misrep,comment) )
library(tidyverse) ## for efficient cleaning of data frames
library(wru) ## for predicting race of profs
library(foreign) ## for reading in of csv files and such
library(rstudioapi) ## for efficient grabbing of working directory info
library(ggplot2) ## for cool plots
library(irr)
library(arm)
library(peRspective)
library(grid)
###setting directory
main_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(main_wd)
## load in data
chatgpt_df <- read.csv("ml_applied2sample_peRspective_coded342obs.csv")
names(chatgpt_df)
###let's find the correlation between these
misrep_sub <- subset(chatgpt_df,select=c(text_id,out_misrep,openai_is_misrep_prob,openai_somewhat_misrep_prob,
openai_not_misrep_prob))
### now change to long
misrep_sub_long = misrep_sub %>%
gather(key=type,value=probability, -c(text_id,out_misrep) )
## now categorize
misrep_sub_long$group <- "Not misrepresentation"
misrep_sub_long$group[type=="openai_is_misrep_prob"] <- "Misrepresentation"
misrep_sub_long$group[misrep_sub_long$group=="openai_is_misrep_prob"] <- "Misrepresentation"
misrep_sub_long$group[misrep_sub_long$group=="openai_somewhat_misrep_prob"] <- "Somewhat Misrepresentation"
### that worked. Now let's find the IQR.
misrep_sub_long_iqr <- misrep_sub_long %>%
group_by(out_misrep,group) %>%
summarize(med_prob = median(probability), pct25 = quantile(probability,0.25),
pct75=quantile(probability,0.75))
View(misrep_sub_long_iqr)
###let's find the correlation between these
misrep_sub <- subset(chatgpt_df,select=c(text_id,out_misrep,openai_is_misrep_prob,openai_somewhat_misrep_prob,
openai_not_misrep_prob))
### now change to long
misrep_sub_long = misrep_sub %>%
gather(key=type,value=probability, -c(text_id,out_misrep) )
## now categorize
misrep_sub_long$group <- "Not misrepresentation"
misrep_sub_long$group[misrep_sub_long$group=="openai_is_misrep_prob"] <- "Misrepresentation"
misrep_sub_long$group[misrep_sub_long$group=="openai_somewhat_misrep_prob"] <- "Somewhat Misrepresentation"
## now categorize
misrep_sub_long$group <- "Not misrepresentation"
misrep_sub_long$group[misrep_sub_long$type=="openai_is_misrep_prob"] <- "Misrepresentation"
misrep_sub_long$group[misrep_sub_long$type=="openai_somewhat_misrep_prob"] <- "Somewhat Misrepresentation"
### that worked. Now let's find the IQR.
misrep_sub_long_iqr <- misrep_sub_long %>%
group_by(out_misrep,group) %>%
summarize(med_prob = median(probability), pct25 = quantile(probability,0.25),
pct75=quantile(probability,0.75))
test_ggplot_reg <- ggplot(misrep_sub_long_iqr, aes(x=out_misrep, y=med_prob, group=as.factor(group),
col=as.factor(group))) +
geom_line(linewidth=1.2) +
geom_ribbon(aes(ymin=pct25,ymax=pct75), alpha=0.4) + #### very important command; makes the CIs
theme_minimal()
test_ggplot_reg
test_ggplot_reg <- ggplot(misrep_sub_long_iqr, aes(x=out_misrep, y=med_prob, group=as.factor(group),
col=as.factor(group),fill=as.factor(group))) +
geom_line(linewidth=1.2) +
geom_ribbon(aes(ymin=pct25,ymax=pct75), alpha=0.4) + #### very important command; makes the CIs
theme_minimal()
test_ggplot_reg
11^8
library(tidyverse) ## for efficient cleaning of data frames
library(wru) ## for predicting race of profs
library(foreign) ## for reading in of csv files and such
library(rstudioapi) ## for efficient grabbing of working directory info
library(ggplot2) ## for cool plots
library(irr)
library(arm)
library(peRspective)
library(grid)
###setting directory
main_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(main_wd)
### api key
pr_api <- "AIzaSyBcW836khRPsqS-Fkkm7P0LNfk4B98_sZ0"
persp_all_output <- readRDS("peRspective_data_test_run06242023.rds")
rmp_df_persp_sub <- read.csv("sample_peRspective_coded342obs.csv")
ggplot_persp <- ggplot(rmp_df_persp_sub, aes(x=aggregate_outrage,fill=as.factor(coded_toxic))) +
geom_density(alpha=0.4) + #### very important command; makes the CIs
theme_minimal() + ## cleans up the presentation of the plot
labs(title="Comparison of normalized aggregation of peRspective scoring",
x="Normalized peRspective aggregate scores", y="Density",
caption=paste0("This plot was generated on ", Sys.Date(),sep="\n",
"By the Ohio Northern University SET-SURF Center."))+
scale_fill_discrete(name = "Manual coding", labels = c("Not toxic", "Toxic"))
ggplot_persp
## check quantiles
## first, non toxic
quantile(persp_rmp_output_nt$aggregate_outrage, seq(0,1,by=0.05))
## subset again, just in case
persp_rmp_output_nt <- subset(persp_rmp_output_nt,coded_toxic==0 )
persp_rmp_output <- subset(persp_rmp_output,coded_toxic==1 )
## Let's check the toxic dim alone
quantile(persp_rmp_output$TOXIC, seq(0,1,by=0.05))
persp_all_output <- readRDS("peRspective_data_test_run06242023.rds")
## subset again, just in case
persp_rmp_output_nt <- subset(persp_all_output,coded_toxic==0 )
persp_rmp_output <- subset(persp_rmp_output,coded_toxic==1 )
persp_rmp_output <- subset(persp_all_output,coded_toxic==1 )
## Let's check the toxic dim alone
quantile(persp_rmp_output$TOXIC, seq(0,1,by=0.05))
## Let's check the toxic dim alone
quantile(persp_rmp_output$TOXICITY, seq(0,1,by=0.05))
quantile(persp_rmp_output_nt$TOXICITY, seq(0,1,by=0.05))
# the 85th pct to 90th pct, and 90th to 95th. What's going on? Let's check
quantile(persp_rmp_output_nt$TOXICITY, seq(0.85,1,by=0.01))
persp_rmp_output_nt_false_pos <- subset(persp_rmp_output_nt, TOXICITY > 0.148)
persp_rmp_output_nt_false_pos$text_id
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[1]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[2]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[3]]
## 3 is definitely neg and not constructive
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[4]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[5]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[6]]
# critiquing those who cannot do well in the class
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[7]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[8]]
# and negative. Not constructive
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[9]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[10]]
# constructive
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[11]]
# actually be an insult in my mind
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[12]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[1]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[2]]
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[3]]
## Let's check the toxic dim alone
quantile(persp_rmp_output$TOXICITY, seq(0,1,by=0.05))
persp_rmp_output_nt_false_pos$text_id # length of 12
## Let's check the toxic dim alone
quantile(persp_rmp_output$TOXICITY, seq(0,1,by=0.05))
quantile(persp_rmp_output_nt$TOXICITY, seq(0,1,by=0.05)) ## looking at non toxic, there is a big jump at
# the 85th pct to 90th pct, and 90th to 95th. What's going on? Let's check
quantile(persp_rmp_output_nt$TOXICITY, seq(0.85,1,by=0.01))
## what about above the 30% threshold? Top 95% of comments
persp_rmp_output_nt_false_pos <- subset(persp_rmp_output_nt, TOXICITY > 0.3)
persp_rmp_output_nt_false_pos <- subset(persp_rmp_output_nt, TOXICITY > 0.148)
## what about above the 30% threshold? Top 95% of comments
persp_rmp_output_nt_false_pos2 <- subset(persp_rmp_output_nt, TOXICITY > 0.3)
persp_rmp_output_nt_false_pos2$text_id
persp_rmp_output_nt_false_pos$text_id # length of 12
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[5]] # Hell is trigger
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[8]] # defn critical,
# actually be an insult in my mind
rmp_df_persp_sub$comment[rmp_df_persp_sub$text_id==persp_rmp_output_nt_false_pos$text_id[12]] # neg on boring,
6.62 - 5.92
0.7/360
(0.7/360)*100
